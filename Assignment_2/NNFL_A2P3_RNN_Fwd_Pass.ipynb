{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NNFL_A2P3_RNN_Fwd_Pass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb66dcd425314d559e42334070e4836b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6265842f48be47c59e27aff3a8b3e1b4",
              "IPY_MODEL_f0b00261996843c49b3cdff666e97bca",
              "IPY_MODEL_ea6ab78e21e04255b2ab12971d01d7f3"
            ],
            "layout": "IPY_MODEL_c8a3c29b045542928d93c5564287af11"
          }
        },
        "6265842f48be47c59e27aff3a8b3e1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f906bce1a9c4a1188c7ddb5a9ba2b6f",
            "placeholder": "​",
            "style": "IPY_MODEL_a13d045a37684841b231a2a7aed7c78b",
            "value": "Reading GloVe Embeddings: 100%"
          }
        },
        "f0b00261996843c49b3cdff666e97bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d32bce16195c4d49afb2384f8fe06242",
            "max": 400000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5205f947d2d841718e063a1b011d700d",
            "value": 400000
          }
        },
        "ea6ab78e21e04255b2ab12971d01d7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd3e011a41194319b0ce378525a1d40d",
            "placeholder": "​",
            "style": "IPY_MODEL_91136809a253414588806501097481bc",
            "value": " 400000/400000 [00:09&lt;00:00, 52423.61it/s]"
          }
        },
        "c8a3c29b045542928d93c5564287af11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f906bce1a9c4a1188c7ddb5a9ba2b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a13d045a37684841b231a2a7aed7c78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d32bce16195c4d49afb2384f8fe06242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5205f947d2d841718e063a1b011d700d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd3e011a41194319b0ce378525a1d40d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91136809a253414588806501097481bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "IF-dv2i-E2rS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to the second NNFL assignment. In this assignment you will be programming an RNN from scratch and creating a preproccessing pipeline for Natural Language Processing. While RNNs are typically programmed using frameworks like PyTorch, the preprocessing pipeline that you will learn about here will be applicable in a lot of NLP problems you will face.\n",
        "\n",
        "Please read the instructions given below carefully before attempting the assignment.  \n",
        "- Do NOT import any other modules\n",
        "- Do NOT change the prototypes of any of the functions\n",
        "- Sample test cases are already given, test your code using these sample cases\n",
        "- Grading will be based on hidden test cases\n",
        "- Please solve this notebook using [Google Colab](https://colab.research.google.com/) as the required packages are already installed "
      ],
      "metadata": {
        "id": "oU7CZ9X2xcJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
        "\n",
        "Make sure you fill in any place that says `YOUR CODE HERE`, as well as your name and ID number below:"
      ],
      "metadata": {
        "id": "YMonCIu5vq9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = \"Harshit Agarwal\"\n",
        "ID = \"2019A3PS0245P\""
      ],
      "metadata": {
        "id": "4QXpkM3O8IhT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing the Dataset and the GloVe embeddings"
      ],
      "metadata": {
        "id": "WDjBIyzkwT8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will kick things off by installing all the pretrained models and the dataset. Running the below cell should set you up.\n",
        "\n",
        "While glove embeddings would have been covered in class, you can find some links about them below:\n",
        "\n",
        "1. [Glove paper](https://nlp.stanford.edu/pubs/glove.pdf)\n",
        "2. [For the lazy ones](https://towardsdatascience.com/light-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010)"
      ],
      "metadata": {
        "id": "8K2YTcH_v6Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "! unzip glove.6B.zip\n",
        "! rm glove.6B.100d.txt glove.6B.200d.txt glove.6B.300d.txt glove.6B.zip\n",
        "! pip install --upgrade --no-cache-dir gdown\n",
        "! gdown --id 1sfQ2Y6kvmrScWMOt4c2zKYxfws5Ivu7x"
      ],
      "metadata": {
        "id": "1PZMWiSep0aN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e98246-c738-4e39-98aa-a83b20788077"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-04 17:18:35--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-04-04 17:18:35--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.08MB/s    in 2m 41s  \n",
            "\n",
            "2022-04-04 17:21:17 (5.09 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: rm: cannot remove 'glove.6B.100d.txt': No such file or directory\n",
            "rm: cannot remove 'glove.6B.200d.txt': No such file or directory\n",
            "rm: cannot remove 'glove.6B.300d.txt': No such file or directory\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sfQ2Y6kvmrScWMOt4c2zKYxfws5Ivu7x\n",
            "To: /content/RNN_From_Scratch_Dataset.txt\n",
            "100% 592k/592k [00:00<00:00, 109MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the requisite libraries. Keep in mind the ones that are imported - you will be needing them at a later point."
      ],
      "metadata": {
        "id": "scO0QLY4xUBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BSyzuofb1PXX"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement"
      ],
      "metadata": {
        "id": "grOOyzwW1URn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem we will try to solve is next word prediction. Given a sequence of words, we want to train an RNN cell to predict the next most probable word."
      ],
      "metadata": {
        "id": "XKCDcr5C1VuI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell initialises all your parameters in the model. Each of these will be explained in due course of time."
      ],
      "metadata": {
        "id": "IVp2QxBdA8Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 8\n",
        "VOCAB_SIZE = 6000\n",
        "EMB_DIM = 50\n",
        "HIDDEN_LEN = 64\n",
        "BATCH_SIZE = 64\n",
        "DATA_PATH = '/content/RNN_From_Scratch_Dataset.txt'"
      ],
      "metadata": {
        "id": "tWUhSvFAA54Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing [3.25M]"
      ],
      "metadata": {
        "id": "U43E0qrJ1RT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing of data involves the following steps for each line of your dataset:\n",
        "1. Remove all punctuation from the data. This is done so that our model does not encounter characters which will not contribute to the prediction of the next word.\n",
        "2. Convert the data into tokens - in this case the tokens would just be words. You should have a clear understanding of the difference between words and tokens.\n",
        "3. Pad the token sequence with padding tokens, or slice it depending on its length. This is done so that all your datapoints are of the same length. This allows us to ensure that when pytorch creates a batch, no errors are encountered. The inspiration for padding, however, comes from transformers. You can read more about them [here](https://arxiv.org/abs/1706.03762)."
      ],
      "metadata": {
        "id": "FQ4rQ8Ka0Frb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first write functions for each of these individual tasks. Note that each of these will be for a single datapoint."
      ],
      "metadata": {
        "id": "N2gG_oCt1s8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED - 0.5 Marks\n",
        "def clean_str(line):\n",
        "\t'''\n",
        "\t\tRemove punctuation marks from the input strings\n",
        "    chars_to_remove = [',', '.', '\"', \"'\", '/', '*', ',', '?', '!', '-', '\\n', '“', '”', '_', '&', '\\ufeff', '&', ';', \":\"]\n",
        "\t\t\n",
        "\t\tArguments:\n",
        "\t\t\tline: The raw text string\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tLowercased string without punctuation marks\n",
        "\t'''\n",
        "\t# YOUR CODE HERE\n",
        "\tchars_to_remove = [',', '.', '\"', \"'\", '/', '*', ',', '?', '!', '-', '\\n', '“', '”', '_', '&', '\\ufeff', '&', ';', \":\"]\n",
        "\tfor ele in line:\n",
        "\t\tif ele in chars_to_remove:\n",
        "\t\t\tline = line.replace(ele,\"\")\n",
        "\treturn line.lower()"
      ],
      "metadata": {
        "id": "aR16p2Fn1rki"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Test Case\n",
        "test_str = 'Who, let* the. dogs- out?'\n",
        "assert ',' not in clean_str(test_str) and '*' not in clean_str(test_str) and '?' not in clean_str(test_str)\n",
        "print('Sample Test passed', '\\U0001F44D')"
      ],
      "metadata": {
        "id": "d9NLS0BW_5vZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b89f2d-fc92-42aa-ab58-d7e88b604cbf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Test passed 👍\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tokeniser is a model that splits our words into tokens. Since our problem is next word prediction, our tokeniser function tokenises the words by splitting them, therefore this is called a Word Tokeniser. You can read about other types of tokenisers [here](https://huggingface.co/docs/transformers/tokenizer_summary)"
      ],
      "metadata": {
        "id": "sGzGjMa24Suk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED - 0.5 Marks\n",
        "def tokenise(line):\n",
        "\t'''\n",
        "\t\tTokenise the raw string into word tokens\n",
        "\t\t\n",
        "\t\tArguments:\n",
        "\t\t\tline: The raw text string\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tTokens in the string, split at a space\n",
        "\t'''\n",
        "\t# YOUR CODE HERE\n",
        "\ttokens = line.split()\n",
        "\treturn tokens"
      ],
      "metadata": {
        "id": "GaUA4Exs1YOR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Test Case\n",
        "test_str = 'Who let the dogs out\\n'\n",
        "assert tokenise(test_str) == ['Who', 'let', 'the', 'dogs', 'out']\n",
        "print('Sample Test passed', '\\U0001F44D')"
      ],
      "metadata": {
        "id": "B-_JFruDAhoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84f9817-c274-4819-89bc-36d0f933d818"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Test passed 👍\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All our training points should have the same length. This is done to ensure that the pytorch dataloader can use them with minimal effort from our side.\n",
        "\n",
        "Another reason for this is that RNNs operate sequentially. Having, say, 200 tokens per training point(which might just be true for our dataset) will cause the training process to slow down. Moreover, RNNs struggle with long sequences.\n",
        "\n",
        "**Note:** Since this function works with preprocessed raw strings, we can also use it to create our labels. Therefore, before slicing/padding, ensure that you have extracted the label and have updated the training datapoint accordingly."
      ],
      "metadata": {
        "id": "6FU_fMOs35hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED - 0.75 Marks\n",
        "def pad_sequence(tokens, seq_len, padding_token = '<PAD>'):\n",
        "\t'''\n",
        "\t\tPadding/slicing sequences of tokens to ensure all of them have the same length. After the padding is done, the next word label is also appended to it.\n",
        "\t\t\n",
        "\t\tArguments:\n",
        "\t\t\ttokens: tokens generated from the tokenizer\n",
        "\t\t\tseq_len: The maximum permitted length of the sequence\n",
        "\t\t\tpadding_token: The token to be used in case of padding\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\ttokens: A list of padded/sliced tokens of len = max_len\n",
        "\t\t\tlast_token: The label for one datapoint, the token with the highest index\n",
        "\t'''\n",
        "\t# YOUR CODE HERE\n",
        "\tcount=1\n",
        "\ts = len(tokens);\n",
        "\tif s==0:\n",
        "\t\tfor i in range(seq_len):\n",
        "\t\t\ttokens.append(padding_token);\n",
        "\t\t\tlast_token='';\n",
        "\telse:\n",
        "\t\tlast_token=tokens[s-1]\n",
        "\t\ttokens[s-1]=padding_token\n",
        "\t\tif s-1<seq_len:\n",
        "\t\t\t\n",
        "\t\t\tfor i in range(s,seq_len):\n",
        "\t\t\t\ttokens.append(padding_token)\n",
        "\t\telif s-1>seq_len:\n",
        "\t\t\ttokens =tokens[0:seq_len];\n",
        "\t\telse:\n",
        "\t\t\ttokens=tokens[0:seq_len];\n",
        "\n",
        "\n",
        "\treturn tokens, last_token"
      ],
      "metadata": {
        "id": "O8wbDshU3lgl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Test Case\n",
        "test_seq = ['Who', 'let', 'the', 'dogs', 'out']\n",
        "tokens, last_token = pad_sequence(test_seq, SEQ_LEN)\n",
        "print(tokens)\n",
        "assert tokens == ['Who', 'let', 'the', 'dogs', '<PAD>', '<PAD>', '<PAD>', '<PAD>'] and last_token == 'out'\n",
        "print('Sample Test passed', '\\U0001F44D')"
      ],
      "metadata": {
        "id": "7oJQaQAuA3VU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97005a6a-0bfe-4476-f432-191cec2436c2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Who', 'let', 'the', 'dogs', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "Sample Test passed 👍\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the above functions should now be called from one function, which will preprocess the entire dataset."
      ],
      "metadata": {
        "id": "5GeIBn8X3s7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED - 1.5 Marks\n",
        "def preprocess_data(path, vocab_size, seq_len):\n",
        "\t'''\n",
        "\t\tFunction to call all preprocessing steps for the entire corpus\n",
        "\n",
        "\t\tNote: Ensure to leave a slot in the vocabulary for the <UNK> token\n",
        "\t\t\n",
        "\t\tArguments:\n",
        "\t\t\tpath: The path to your data file\n",
        "\t\t\tvocab_size: The number of tokens to be included in the vocabulary\n",
        "\t\t\tseq_len: The maximum permitted length of the token sequences\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tdatapoints: The preprocessed training + testing points for the corpus, list format\n",
        "      labels: The labels to be used per datapoint, list format\n",
        "\t'''\n",
        "\t# YOUR CODE HERE\n",
        "\ttext = open(path,\"r\");\n",
        "\t# print(text.readlines())\n",
        " \n",
        "\tdatapoints=[]\n",
        "\tlabels=[]\n",
        "\tfor x in text:\n",
        "\t\tline = clean_str(x);\n",
        "\n",
        "\t\ttokens = tokenise(line);\n",
        "\n",
        "\t\ttokens=tokens[0:vocab_size-1];\n",
        "\t\t[datapoint, label] =pad_sequence(tokens,seq_len)\n",
        "\t\tdatapoints.append(datapoint)\n",
        "\t\tlabels.append(label)\n",
        "\t\n",
        "\t\n",
        "\n",
        "\treturn datapoints, labels"
      ],
      "metadata": {
        "id": "1zNt-wkF0FBQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below cell to preprocess your data."
      ],
      "metadata": {
        "id": "vbdWybl2BQya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datapoints, labels = preprocess_data(DATA_PATH, VOCAB_SIZE, SEQ_LEN)\n"
      ],
      "metadata": {
        "id": "YP52HLLGBOx-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Test Case\n",
        "assert len(datapoints[0]) == len(datapoints[-1]) == len(datapoints[1231]) == SEQ_LEN\n",
        "assert len(labels) == len(datapoints)\n",
        "print('Sample Test passed', '\\U0001F44D')"
      ],
      "metadata": {
        "id": "-xD5qxXYjv0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46730ea-9b76-4f88-a6d0-61bd0e59a84c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Test passed 👍\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the vocab and converting the tokens to numbers [1.25M]"
      ],
      "metadata": {
        "id": "sXoz96tj6ACJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More often than not, you will have a lot of words in your dataset - more than you require. Therefore, VOCAB_SIZE becomes a parameter that you can manually set as per your requirements.\n",
        "\n",
        "Your model cannot work with textual words - it needs numbers. For this purpose, we convert the words into numbers by creating a one-one mapping between words and a set of indices.\n",
        "\n",
        "For creating the vocabulary, we will be choosing the top-k words(k = user-defined vocabulary size) in our dataset. We also need a way to work with words not in our vocab - thus comes the ```<UNK>``` token. Any word not in our vocabulary is allotted this token. This has to manually be added into the dataset.\n",
        "\n",
        "We will also create an inverse mapping which can be used for decoding the next word from our model."
      ],
      "metadata": {
        "id": "VO8Q7Cvo6FYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(datapoints, labels, vocab_size):\n",
        "\t'''\n",
        "\t\tBuilding the vocabulary from the most common words in the corpus\n",
        "\n",
        "\t\tNote: Ensure to leave a slot in the vocabulary for the <UNK> token. \n",
        "\t\tFor uniformity, insert this at the end of your vocab, ie, its index should be 4999.\n",
        "\t\tAlso ensure that each label is in the vocab. If not, add it by removing the least common word.\n",
        "\t\tAlso ensure you remove padding tokens from the vocabulary and add the most appropriate word.\n",
        "\t\t\n",
        "\t\tArguments:\n",
        "\t\t\tdatapoints: The preprocessed datapoints in the corpus\n",
        "\t\t\tlabels: The labels per datapoint in the corpus\n",
        "\t\t\tvocab_size: The number of tokens in the vocab\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tvocab: A dicitionary mapping from the word to its corresponding vocab index(0 indexed)\n",
        "\t\t\tvocab_inv: A dicitionary mapping from the vocab index to its corresponding word\n",
        "\t'''\t\n",
        "\tword_sea = []\n",
        "\tfor datapoint in datapoints + labels:\n",
        "\t\tword_sea.extend(datapoint)\n",
        "\n",
        "\tmost_common_words = [word for word, _ in Counter(word_sea).most_common(vocab_size - 1)]\n",
        "\treplaced_idx = 1\n",
        "\tfor label in labels:\n",
        "\t\tif label not in most_common_words:\n",
        "\t\t\twhile(most_common_words[-replaced_idx] in labels):\n",
        "\t\t\t\treplaced_idx += 1\n",
        "\t\t\tmost_common_words[-replaced_idx] = label\n",
        "\t\n",
        "\tvocab = {word: idx for idx, word in enumerate(most_common_words)}\n",
        "\tvocab_inv = {idx: word for idx, word in enumerate(most_common_words)}\n",
        "\tvocab['<UNK>'] = vocab_size - 1\n",
        "\tvocab_inv[vocab_size - 1] = '<UNK>'\n",
        "\treturn vocab, vocab_inv"
      ],
      "metadata": {
        "id": "7tHkfb2O1Wzq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function will convert the tokens in our dataset to tokens in our created vocabulary. This means that tokens not in our vocabulary wil get mapped to ```<UNK>```"
      ],
      "metadata": {
        "id": "WISklrPR7PiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data2tokens(vocab, raw_data):\n",
        "\t'''\n",
        "\t\tConverts the raw text into their corresponding tokens\n",
        "\t\t\n",
        "\t\tArguments:\n",
        "\t\t\tvocab: Mapping from the word to its corresponding vocab index\n",
        "\t\t\traw_data: The preprocessed data, however, some words are not present as \n",
        "\t\t\t\t\t\t\t  tokens in the vocab\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tdataset_tokens: A list of the preprocessed data where all words are correspoding to \n",
        "\t\t\t\t\t\t\t\t\t    tokens in the vocab\n",
        "\t'''\n",
        "\tdataset_tokens = []\n",
        "\tfor data in raw_data:\n",
        "\t\tdataset_tokens.append([word if word in vocab else '<UNK>' for word in data])\n",
        "\t\n",
        "\treturn dataset_tokens"
      ],
      "metadata": {
        "id": "CNwRF3Y27PAk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above tokens can now mapped to indices in our vocab."
      ],
      "metadata": {
        "id": "hFMDZMWm7t1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED - 1.25 Marks\n",
        "def tokens2ids(vocab, data_tokens):\n",
        "\t'''\n",
        "\t\tConverts the tokens into their corresponding vocab indices\n",
        "\t\t\n",
        "\t\tArguments:\n",
        "\t\t\tvocab: Mapping from the word to its corresponding vocab index\n",
        "\t\t\tdata_tokens: The preprocessed data where all words are correspoding to \n",
        "\t\t\t\t\t\t\t\t\t tokens in the vocab\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tdataset_ids: The tokens in the dataset converted to their vocab indices\n",
        "\t\t\tThis should be a Pytorch Long Tensor\n",
        "\t'''\n",
        "\t# YOUR CODE HERE\n",
        "\tdataset_ids=[]\n",
        "\n",
        "\tfor t in data_tokens:\n",
        "\t\ttemp=[]\n",
        "\t\t# print(t);\n",
        "\t\t# print(\"\\n\");\n",
        "\t\t# print(len(t))\n",
        "\t\tfor y in t:\n",
        "\t\t\ttemp.append(vocab[y]);\n",
        "\t\tdataset_ids.append(temp);\n",
        "\n",
        "\t# dataset_ids=torch.FloatTensor(dataset_ids).long()\n",
        "\t\n",
        "\n",
        "\tdataset_ids = torch.tensor(dataset_ids).long()\n",
        "\n",
        "\t\n",
        "\treturn dataset_ids"
      ],
      "metadata": {
        "id": "CE2MWnYF2WzG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below cell to call all the functions above in sequence."
      ],
      "metadata": {
        "id": "VAjmy8498B3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab, vocab_inv = build_vocab(datapoints, labels, VOCAB_SIZE)\n",
        "print(vocab)\n",
        "dataset_tokens = data2tokens(vocab, datapoints)\n",
        "dataset_ids = tokens2ids(vocab, dataset_tokens)\n",
        "# print(dataset_ids)\n",
        "# print(len(dataset_tokens))"
      ],
      "metadata": {
        "id": "ADQMNCBX8BWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d04f82-730f-45f1-b030-94cfcbb942d2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<PAD>': 0, 'e': 1, 'a': 2, 'i': 3, 't': 4, 'the': 5, 'o': 6, 'n': 7, 's': 8, 'h': 9, 'r': 10, 'and': 11, 'l': 12, 'd': 13, 'to': 14, 'of': 15, 'm': 16, 'u': 17, 'that': 18, 'it': 19, 'in': 20, 'c': 21, 'y': 22, 'you': 23, 'was': 24, 'he': 25, 'w': 26, 'f': 27, 'g': 28, 'is': 29, 'his': 30, 'p': 31, 'have': 32, 'b': 33, 'my': 34, 'as': 35, 'had': 36, 'with': 37, 'which': 38, 'at': 39, 'for': 40, 'but': 41, 'not': 42, 'me': 43, 'be': 44, 'v': 45, 'said': 46, 'k': 47, 'we': 48, 'there': 49, 'holmes': 50, 'this': 51, 'from': 52, 'upon': 53, 'she': 54, 'her': 55, 'very': 56, '’': 57, 'so': 58, 'your': 59, 'what': 60, 'no': 61, 'him': 62, 'been': 63, 'on': 64, 'were': 65, 'all': 66, 'by': 67, 'then': 68, 'one': 69, 'are': 70, 'an': 71, 'out': 72, 'when': 73, 'would': 74, 'mr': 75, 'little': 76, 'up': 77, 'will': 78, 'has': 79, 'into': 80, 'man': 81, 'could': 82, 'who': 83, 'do': 84, 'if': 85, 'some': 86, 'now': 87, 'see': 88, 'should': 89, 'down': 90, 'well': 91, 'they': 92, 'may': 93, 'our': 94, 'or': 95, 'think': 96, 'over': 97, 'am': 98, 'shall': 99, 'did': 100, 'about': 101, 'than': 102, 'more': 103, 'only': 104, 'must': 105, 'before': 106, 'can': 107, 'other': 108, 'come': 109, 'yes': 110, 'know': 111, 'us': 112, 'how': 113, 'them': 114, 'time': 115, 'came': 116, 'two': 117, 'where': 118, 'back': 119, 'much': 120, 'sherlock': 121, 'door': 122, 'might': 123, 'however': 124, 'any': 125, 'heard': 126, 'just': 127, 'quite': 128, 'face': 129, 'found': 130, 'good': 131, 'here': 132, 'oh': 133, 'such': 134, 'nothing': 135, 'matter': 136, 'away': 137, 'never': 138, 'case': 139, 'room': 140, 'made': 141, 'their': 142, 'way': 143, 'miss': 144, 'took': 145, 'hand': 146, 'like': 147, 'eyes': 148, 'house': 149, 'x': 150, 'own': 151, 'after': 152, 'first': 153, 'last': 154, 'find': 155, 'tell': 156, 'morning': 157, 'yet': 158, 'go': 159, 'having': 160, 'saw': 161, 'long': 162, 'side': 163, 'sir': 164, 'watson': 165, 'every': 166, 'say': 167, 'through': 168, 'these': 169, 'too': 170, 'himself': 171, 'st': 172, 'street': 173, 'few': 174, 'right': 175, 'make': 176, 'let': 177, 'most': 178, 'still': 179, 'myself': 180, 'cried': 181, 'young': 182, 'take': 183, 'left': 184, 'once': 185, 'rather': 186, 'seemed': 187, 'thought': 188, 'window': 189, 'perhaps': 190, 'father': 191, 'round': 192, 'until': 193, 'small': 194, 'three': 195, 'day': 196, 'something': 197, 'its': 198, 'while': 199, 'those': 200, 'indeed': 201, 'without': 202, 'why': 203, 'seen': 204, 'friend': 205, 'lady': 206, 'asked': 207, 'look': 208, 'cannot': 209, 'q': 210, 'name': 211, 'between': 212, 'ever': 213, 'course': 214, 'great': 215, 'even': 216, 'off': 217, 'night': 218, 'hands': 219, 'chair': 220, 'done': 221, 'brought': 222, 'years': 223, 'went': 224, 'business': 225, 'again': 226, 'give': 227, 'old': 228, 'open': 229, 'head': 230, 'though': 231, 'enough': 232, 'understand': 233, 'strange': 234, 'really': 235, 'put': 236, 'light': 237, 'j': 238, 'hardly': 239, 'both': 240, 'always': 241, 'doubt': 242, 'remarked': 243, 'also': 244, 'same': 245, '‘i': 246, 'knew': 247, 'against': 248, 'dear': 249, 'answered': 250, 'pray': 251, 'gave': 252, 'whole': 253, 'far': 254, 'better': 255, 'told': 256, 'front': 257, 'suddenly': 258, 'looked': 259, 'gentleman': 260, 'anything': 261, 'turned': 262, 'within': 263, 'got': 264, 'set': 265, 'place': 266, 'woman': 267, 'being': 268, 'get': 269, 'lord': 270, 'thing': 271, 'point': 272, 'certainly': 273, 'leave': 274, 'passed': 275, 'black': 276, 'many': 277, 'already': 278, 'looking': 279, 'another': 280, 'lestrade': 281, '—': 282, 'word': 283, 'help': 284, 'clear': 285, 'mind': 286, 'days': 287, 'sat': 288, 'hair': 289, 'possible': 290, 'police': 291, 'gone': 292, 'believe': 293, 'table': 294, 'papers': 295, 'soon': 296, 'wish': 297, 'home': 298, 'hat': 299, 'save': 300, 'whether': 301, 'ah': 302, 'together': 303, 'words': 304, 'simon': 305, 'half': 306, 'since': 307, 'london': 308, 'paper': 309, 'doctor': 310, 'does': 311, 'sure': 312, 'behind': 313, 'forward': 314, 'life': 315, 'son': 316, 'under': 317, 'work': 318, 'across': 319, 'men': 320, 'returned': 321, 'among': 322, 'minutes': 323, 'mrs': 324, 'opened': 325, 'z': 326, 'singular': 327, 'either': 328, 'call': 329, 'able': 330, 'least': 331, 'instant': 332, 'fellow': 333, '£': 334, 'mccarthy': 335, 'rucastle': 336, 'yourself': 337, 'wife': 338, 'large': 339, 'five': 340, 'o’clock': 341, 'walked': 342, 'near': 343, 'ten': 344, 'several': 345, 'fire': 346, 'lay': 347, 'given': 348, 'interest': 349, 'read': 350, 'ask': 351, 'hope': 352, 'during': 353, 'spoke': 354, 'each': 355, 'baker': 356, 'hear': 357, 'hour': 358, 'none': 359, 'became': 360, 'it’s': 361, 'else': 362, 'question': 363, 'mine': 364, 'laid': 365, 'client': 366, 'felt': 367, 'goose': 368, 'inspector': 369, '‘': 370, 'things': 371, 'strong': 372, 'family': 373, 'dark': 374, 'corner': 375, 'facts': 376, 'money': 377, 'entered': 378, 'absolutely': 379, 'seems': 380, 'end': 381, 'rushed': 382, 'ran': 383, 'thank': 384, 'met': 385, 'waiting': 386, 'going': 387, 'god': 388, 'moment': 389, 'whom': 390, 'sprang': 391, 'use': 392, 'road': 393, 'less': 394, 'hard': 395, 'evening': 396, 'stood': 397, 'keep': 398, '‘you': 399, 'colonel': 400, 'week': 401, 'don’t': 402, 'observed': 403, 'carried': 404, 'appeared': 405, 'letters': 406, 'quick': 407, 'lane': 408, 'remember': 409, 'struck': 410, 'silence': 411, 'companion': 412, 'afraid': 413, 'crime': 414, 'above': 415, 'stone': 416, 'led': 417, 'rooms': 418, 'story': 419, 'manner': 420, 'seven': 421, 'country': 422, 'clothes': 423, 'note': 424, 'heavy': 425, 'part': 426, 'visitor': 427, 'because': 428, 'whose': 429, 'likely': 430, 'drove': 431, 'best': 432, 'new': 433, 'used': 434, 'grey': 435, 'ready': 436, 'letter': 437, 'drawn': 438, 'sister': 439, 'dr': 440, '1': 441, 'threw': 442, 'sound': 443, 'want': 444, 'rose': 445, 'glanced': 446, 'doing': 447, 'close': 448, 'four': 449, 'people': 450, 'began': 451, 'started': 452, 'turner': 453, 'cry': 454, 'white': 455, 'air': 456, 'true': 457, 'red': 458, 'won’t': 459, 'square': 460, 'colour': 461, 'obvious': 462, 'coming': 463, 'floor': 464, 'ourselves': 465, 'known': 466, 'glancing': 467, 'occurred': 468, 'cut': 469, 'bed': 470, 'nature': 471, 'imagine': 472, 'six': 473, 'appears': 474, 'ha': 475, 'followed': 476, 'interesting': 477, 'step': 478, 'deep': 479, 'past': 480, 'majesty': 481, 'next': 482, 'windows': 483, 'fear': 484, 'standing': 485, 'mean': 486, 'afterwards': 487, 'alone': 488, 'fresh': 489, 'dressed': 490, 'reason': 491, 'redheaded': 492, 'short': 493, 'ago': 494, 'idea': 495, 'stepfather': 496, 'beside': 497, 'cold': 498, 'finally': 499, 'shown': 500, 'laughing': 501, 'account': 502, 'death': 503, 'person': 504, 'bring': 505, 'bedroom': 506, 'quietly': 507, 'details': 508, 'cab': 509, 'pulled': 510, 'whispered': 511, 'towards': 512, 'married': 513, 'husband': 514, 'called': 515, 'year': 516, 'wilson': 517, 'considerable': 518, 'effect': 519, 'sight': 520, 'experience': 521, 'anyone': 522, 'feet': 523, 'i’ll': 524, 'reading': 525, 'hosmer': 526, 'mother': 527, 'evidence': 528, 'bent': 529, 'lamp': 530, 'clair': 531, 'blue': 532, 'remained': 533, 'almost': 534, 'someone': 535, 'mystery': 536, 'glance': 537, 'shoulders': 538, 'confess': 539, 'taken': 540, 'slowly': 541, 'king': 542, 'laughed': 543, 'daughter': 544, 'present': 545, 'times': 546, 'remarkable': 547, 'important': 548, 'turn': 549, 'wait': 550, '‘and': 551, 'john': 552, 'lost': 553, 'quiet': 554, 'marriage': 555, 'sort': 556, 'heart': 557, 'need': 558, 'simple': 559, 'held': 560, 'late': 561, 'closed': 562, 'cases': 563, 'city': 564, 'girl': 565, 'office': 566, 'everything': 567, 'ground': 568, 'speak': 569, 'mary': 570, 'windibank': 571, 'silent': 572, 'seeing': 573, 'coroner': 574, 'miles': 575, 'neville': 576, 'irene': 577, 'position': 578, 'extraordinary': 579, 'figure': 580, 'observe': 581, 'tonight': 582, 'matters': 583, 'sent': 584, 'peculiar': 585, 'therefore': 586, 'passage': 587, 'outside': 588, 'address': 589, 'trust': 590, 'excuse': 591, 'surprise': 592, 'sign': 593, 'photograph': 594, 'line': 595, 'view': 596, '‘the': 597, 'chance': 598, 'cause': 599, 'station': 600, 'pocket': 601, 'entirely': 602, 'excellent': 603, 'dropped': 604, 'direction': 605, 'dead': 606, 'making': 607, 'eye': 608, 'safe': 609, 'glad': 610, 'problem': 611, 'body': 612, 'seem': 613, 'weeks': 614, 'didn’t': 615, '‘oh': 616, 'written': 617, 'waited': 618, 'points': 619, 'attention': 620, 'happened': 621, 'shook': 622, 'along': 623, 'james': 624, 'talk': 625, 'pool': 626, 'instantly': 627, 'town': 628, 'stoner': 629, 'dreadful': 630, 'coronet': 631, 'armchair': 632, 'fancy': 633, 'itself': 634, 'order': 635, 'hall': 636, 'examined': 637, 'sharp': 638, 'there’s': 639, 'england': 640, 'boots': 641, 'caught': 642, 'absolute': 643, 'follow': 644, 'serious': 645, 'hundred': 646, 'afternoon': 647, 'character': 648, 'suppose': 649, 'reached': 650, 'sittingroom': 651, 'witness': 652, 'nearly': 653, 'holmes’': 654, 'expected': 655, 'easy': 656, 'neither': 657, 'show': 658, 'carriage': 659, 'centre': 660, 'showed': 661, 'change': 662, 'listened': 663, 'events': 664, 'dress': 665, 'advertisement': 666, 'answer': 667, '‘no': 668, 'happy': 669, 'claim': 670, 'smiling': 671, 'early': 672, 'lying': 673, 'pale': 674, 'surprised': 675, 'advice': 676, 'company': 677, 'lips': 678, 'public': 679, 'danger': 680, 'boscombe': 681, 'hatherley': 682, 'looks': 683, 'innocent': 684, 'caused': 685, 'feeling': 686, 'charge': 687, 'holder': 688, 'break': 689, 'sitting': 690, 'hunter': 691, 'toller': 692, '0': 693, 'love': 694, 'adler': 695, 'results': 696, 'explain': 697, 'importance': 698, 'precisely': 699, 'sit': 700, 'high': 701, 'kindly': 702, 'pretty': 703, 'send': 704, 'gold': 705, 'news': 706, 'deal': 707, 'maid': 708, 'shot': 709, '‘what': 710, 'appearance': 711, 'action': 712, 'contrary': 713, 'besides': 714, 'perfectly': 715, 'engaged': 716, 'fell': 717, 'drew': 718, 'steps': 719, 'questioning': 720, 'evil': 721, 'walking': 722, 'turning': 723, 'fact': 724, 'rest': 725, 'age': 726, 'says': 727, 'ways': 728, '‘it': 729, 'noble': 730, 'yours': 731, 'bird': 732, 'pipe': 733, 'fingers': 734, 'amid': 735, 'merryweather': 736, 'placed': 737, 'blood': 738, 'result': 739, 'features': 740, 'friends': 741, 'opinion': 742, 'kind': 743, 'others': 744, 'throwing': 745, 'means': 746, 'impression': 747, '‘yes': 748, 'although': 749, 'child': 750, 'openshaw': 751, 'terrible': 752, 'geese': 753, 'ventilator': 754, 'feel': 755, 'arthur': 756, 'form': 757, 'following': 758, 'keen': 759, 'tall': 760, 'chamber': 761, 'interested': 762, 'sheet': 763, 'carefully': 764, 'wrote': 765, 'german': 766, 'comes': 767, 'coat': 768, 'rich': 769, 'broad': 770, 'continued': 771, 'opening': 772, 'secret': 773, 'second': 774, 'briony': 775, 'intention': 776, 'certain': 777, 'lock': 778, 'evidently': 779, 'object': 780, 'running': 781, 'search': 782, 'affairs': 783, 'drive': 784, 'nor': 785, 'whatever': 786, 'probably': 787, 'taking': 788, 'influence': 789, 'copper': 790, 'fall': 791, 'poor': 792, 'he’s': 793, 'different': 794, 'slipped': 795, 'possibly': 796, 'jabez': 797, 'heavily': 798, 'league': 799, 'monday': 800, 'full': 801, '‘there': 802, 'clay': 803, 'assistant': 804, 'exceedingly': 805, 'determined': 806, 'loss': 807, 'thin': 808, 'shining': 809, 'nine': 810, 'iron': 811, 'sudden': 812, 'angry': 813, 'start': 814, 'wedding': 815, 'breakfast': 816, 'thumb': 817, 'bright': 818, 'frank': 819, 'train': 820, 'truth': 821, 'trouble': 822, 'uncle': 823, 'america': 824, 'box': 825, 'inside': 826, 'wooden': 827, 'low': 828, 'lascar': 829, 'force': 830, 'adventure': 831, 'reasoning': 832, 'throw': 833, 'complete': 834, 'books': 835, 'spoken': 836, 'practice': 837, 'lived': 838, 'walk': 839, 'can’t': 840, 'easily': 841, 'data': 842, 'scene': 843, 'boy': 844, 'wanted': 845, 'pair': 846, 'fifty': 847, 'marked': 848, 'shrugged': 849, 'promise': 850, 'subject': 851, 'tried': 852, 'tomorrow': 853, 'eight': 854, 'pleasure': 855, 'vanished': 856, 'garden': 857, 'furnished': 858, 'secure': 859, 'saved': 860, 'streets': 861, 'breaking': 862, 'raise': 863, 'number': 864, 'disappeared': 865, 'neighbourhood': 866, 'carry': 867, 'broke': 868, 'seized': 869, 'voice': 870, 'care': 871, 'key': 872, 'pushed': 873, 'saying': 874, 'narrative': 875, 'anxious': 876, 'court': 877, 'learn': 878, 'live': 879, 'worth': 880, 'sake': 881, 'west': 882, 'real': 883, 'water': 884, 'unfortunate': 885, 'hours': 886, 'later': 887, 'knowledge': 888, 'difficult': 889, 'today': 890, 'third': 891, 'sense': 892, 'jones': 893, 'expect': 894, 'yellow': 895, 'edge': 896, 'prisoner': 897, 'longer': 898, 'fashion': 899, 'usual': 900, 'mad': 901, 'prevent': 902, 'grounds': 903, 'worn': 904, 'allowed': 905, 'stairs': 906, 'pointed': 907, 'formed': 908, 'pass': 909, 'return': 910, 'duty': 911, 'dying': 912, 'rain': 913, 'presume': 914, 'beneath': 915, 'swiftly': 916, 'foot': 917, 'grew': 918, 'wrong': 919, 'horsham': 920, 'locked': 921, 'pips': 922, 'horror': 923, 'envelope': 924, 'horrible': 925, 'fixed': 926, 'bradstreet': 927, '2': 928, 'yesterday': 929, 'horner': 930, 'ryder': 931, 'lodgings': 932, 'merely': 933, 'journey': 934, 'example': 935, 'problems': 936, 'wear': 937, 'suit': 938, 'writing': 939, 'raised': 940, 'agent': 941, 'plainly': 942, 'state': 943, 'passing': 944, 'familiar': 945, 'hum': 946, 'private': 947, 'twice': 948, 'herself': 949, 'beautiful': 950, 'marry': 951, 'fortunate': 952, 'lodge': 953, 'shortly': 954, 'investigation': 955, 'english': 956, 'top': 957, 'glass': 958, 'goes': 959, 'continue': 960, 'shouted': 961, 'reach': 962, 'lose': 963, 'twelve': 964, 'expression': 965, 'banker': 966, 'naturally': 967, 'smoke': 968, 'alarm': 969, 'precious': 970, 'broken': 971, 'startled': 972, 'suspicion': 973, 'gives': 974, 'upstairs': 975, 'wished': 976, 'value': 977, 'slight': 978, 'thrust': 979, 'marks': 980, 'vacancy': 981, 'roof': 982, 'couple': 983, 'american': 984, 'shutters': 985, 'backward': 986, '‘my': 987, '‘that': 988, '‘well': 989, '4': 990, 'piece': 991, 'burst': 992, 'knees': 993, 'lawn': 994, 'revolver': 995, 'aside': 996, 'scotland': 997, 'meet': 998, 'signs': 999, 'track': 1000, 'beg': 1001, 'cellar': 1002, 'months': 1003, 'become': 1004, 'presence': 1005, 'smell': 1006, 'notes': 1007, 'pistol': 1008, 'you’ll': 1009, 'touch': 1010, 'explained': 1011, 'clue': 1012, 'discovered': 1013, 'connection': 1014, 'hurried': 1015, 'circle': 1016, 'glasses': 1017, 'hotel': 1018, 'ceiling': 1019, 'finger': 1020, 'law': 1021, 'curious': 1022, 'covered': 1023, 'clearly': 1024, 'paddington': 1025, 'grass': 1026, 'moran': 1027, 'violence': 1028, 'impossible': 1029, 'ordered': 1030, 'explanation': 1031, 'sometimes': 1032, 'narrow': 1033, 'alice': 1034, 'died': 1035, 'cleared': 1036, 'star': 1037, 'learned': 1038, 'twisted': 1039, 'wall': 1040, 'creature': 1041, 'countess': 1042, 'roylott': 1043, 'doran': 1044, 'flora': 1045, 'gems': 1046, 'beeches': 1047, 'winchester': 1048, 'veil': 1049, 'society': 1050, 'soul': 1051, 'deeply': 1052, 'immense': 1053, 'vague': 1054, 'beyond': 1055, 'lit': 1056, 'hot': 1057, 'deduce': 1058, 'thick': 1059, 'hold': 1060, 'bohemia': 1061, 'remains': 1062, 'stay': 1063, 'brown': 1064, 'suggested': 1065, 'straight': 1066, 'suggestive': 1067, 'seat': 1068, 'occasionally': 1069, 'honour': 1070, 'prefer': 1071, 'aware': 1072, 'circumstances': 1073, 'paced': 1074, 'duke': 1075, 'power': 1076, 'acquaintance': 1077, 'prove': 1078, 'bad': 1079, 'pay': 1080, 'drop': 1081, 'situation': 1082, 'ceased': 1083, 'friend’s': 1084, 'pockets': 1085, 'stretched': 1086, 'legs': 1087, 'except': 1088, 'thoroughly': 1089, 'arms': 1090, 'watch': 1091, 'church': 1092, 'twenty': 1093, 'clergyman': 1094, 'then’': 1095, 'park': 1096, 'formidable': 1097, 'remain': 1098, 'general': 1099, 'fine': 1100, 'quarter': 1101, 'dashed': 1102, 'surely': 1103, 'stopped': 1104, 'pavement': 1105, 'wonder': 1106, 'shoulder': 1107, 'woman’s': 1108, 'apology': 1109, 'try': 1110, 'presented': 1111, 'makes': 1112, 'memory': 1113, 'commonplace': 1114, 'frockcoat': 1115, 'waistcoat': 1116, 'apply': 1117, 'offices': 1118, 'earth': 1119, 'market': 1120, '‘why': 1121, 'often': 1122, 'founded': 1123, 'east': 1124, 'folk': 1125, 'orange': 1126, 'stair': 1127, 'filled': 1128, 'ross': 1129, '‘then': 1130, 'bowed': 1131, 'bank': 1132, 'conversation': 1133, 'yard': 1134, 'profession': 1135, 'winding': 1136, 'lantern': 1137, 'single': 1138, 'solved': 1139, 'george': 1140, 'conclusions': 1141, 'convinced': 1142, 'allow': 1143, 'referred': 1144, 'violent': 1145, 'machine': 1146, 'somewhat': 1147, 'father’s': 1148, 'sum': 1149, 'fit': 1150, 'firm': 1151, 'angel': 1152, 'typewritten': 1153, 'speech': 1154, 'handkerchief': 1155, 'statement': 1156, 'strike': 1157, 'unless': 1158, 'lens': 1159, 'catch': 1160, 'leaning': 1161, 'talking': 1162, 'disposition': 1163, 'farther': 1164, 'duties': 1165, 'valley': 1166, 'appear': 1167, 'estate': 1168, 'retained': 1169, 'theory': 1170, 'farm': 1171, 'natural': 1172, 'assistance': 1173, 'examination': 1174, 'spite': 1175, 'difficulty': 1176, 'sofa': 1177, 'probable': 1178, 'returning': 1179, 'blow': 1180, 'painful': 1181, 'lad': 1182, 'knows': 1183, 'spent': 1184, 'ears': 1185, 'trees': 1186, 'tut': 1187, 'possession': 1188, 'cigar': 1189, 'strength': 1190, 'property': 1191, 'shaking': 1192, 'records': 1193, 'bearing': 1194, 'receive': 1195, 'rising': 1196, 'distance': 1197, 'waterloo': 1198, 'wife’s': 1199, 'den': 1200, 'heavens': 1201, 'building': 1202, 'whistle': 1203, 'fainted': 1204, 'finding': 1205, 'madam': 1206, 'trap': 1207, 'downstairs': 1208, 'trivial': 1209, 'cheeks': 1210, 'villain': 1211, 'sister’s': 1212, 'stoke': 1213, 'path': 1214, 'gipsies': 1215, 'band': 1216, 'engineer': 1217, 'stark': 1218, 'world': 1219, 'press': 1220, 'march': 1221, 'patient': 1222, 'study': 1223, 'desire': 1224, 'spare': 1225, 'servant': 1226, 'changed': 1227, 'chuckled': 1228, 'obviously': 1229, 'remove': 1230, 'mark': 1231, 'frequently': 1232, 'lead': 1233, 'signature': 1234, 'consult': 1235, 'recent': 1236, 'nice': 1237, 'height': 1238, 'neck': 1239, 'chin': 1240, 'secrecy': 1241, 'murmured': 1242, 'accustomed': 1243, 'purpose': 1244, 'visit': 1245, 'information': 1246, 'retired': 1247, 'attempts': 1248, 'ruin': 1249, 'shadow': 1250, 'bag': 1251, 'goodnight': 1252, 'inquiry': 1253, 'groom': 1254, 'whence': 1255, 'emerged': 1256, 'heartily': 1257, 'lie': 1258, 'unusual': 1259, 'dozen': 1260, 'heads': 1261, 'norton': 1262, 'inner': 1263, 'field': 1264, 'wondering': 1265, 'run': 1266, 'bridegroom': 1267, 'chain': 1268, 'plans': 1269, 'rely': 1270, 'ordinary': 1271, 'trousers': 1272, 'smile': 1273, 'description': 1274, 'inclined': 1275, 'women': 1276, 'equally': 1277, 'mouth': 1278, 'clouds': 1279, 'bound': 1280, 'finished': 1281, 'habits': 1282, 'youth': 1283, 'i’ve': 1284, 'staggered': 1285, 'scattered': 1286, 'suspicious': 1287, 'flight': 1288, 'future': 1289, 'successful': 1290, 'stared': 1291, 'stout': 1292, 'fingertips': 1293, 'share': 1294, 'greatest': 1295, 'otherwise': 1296, 'dirty': 1297, 'wore': 1298, 'metal': 1299, 'collar': 1300, 'amount': 1301, 'eleven': 1302, 'spirits': 1303, 'household': 1304, 'hole': 1305, 'fortune': 1306, 'shade': 1307, 'managed': 1308, '‘is': 1309, 'duncan': 1310, 'favour': 1311, 'friday': 1312, 'encyclopædia': 1313, 'goodbye': 1314, 'middle': 1315, 'card': 1316, '‘where': 1317, 'saxecoburg': 1318, 'minute': 1319, 'month': 1320, 'french': 1321, 'keenly': 1322, 'conveyed': 1323, 'double': 1324, 'tide': 1325, 'criminal': 1326, 'official': 1327, 'party': 1328, 'dog': 1329, 'detective': 1330, 'stones': 1331, 'gloom': 1332, 'feared': 1333, 'highest': 1334, 'gentle': 1335, 'disappearance': 1336, 'please': 1337, 'fantastic': 1338, 'inquiries': 1339, 'mere': 1340, 'working': 1341, 'puzzled': 1342, 'practical': 1343, 'ring': 1344, 'usually': 1345, 'gazing': 1346, 'ear': 1347, 'nervous': 1348, 'sutherland': 1349, 'astonishment': 1350, 'alive': 1351, 'france': 1352, 'write': 1353, 'that’s': 1354, 'missed': 1355, 'bringing': 1356, 'doors': 1357, 'settled': 1358, 'further': 1359, 'slip': 1360, 'incident': 1361, 'bottom': 1362, 'asking': 1363, 'conviction': 1364, 'professional': 1365, 'sideboard': 1366, 'sorry': 1367, 'breast': 1368, 'fair': 1369, 'kept': 1370, 'appointment': 1371, 'arrested': 1372, 'assizes': 1373, 'credit': 1374, 'angle': 1375, 'anger': 1376, 'remark': 1377, 'consider': 1378, 'thinking': 1379, 'yards': 1380, 'passion': 1381, 'remarks': 1382, 'deadly': 1383, 'medical': 1384, 'county': 1385, 'shone': 1386, 'carrying': 1387, 'impressed': 1388, 'considerably': 1389, 'approached': 1390, 'tobacco': 1391, 'sank': 1392, 'cunning': 1393, 'land': 1394, 'forced': 1395, 'easier': 1396, 'wound': 1397, 'wind': 1398, 'traces': 1399, 'brandy': 1400, 'spend': 1401, 'arrived': 1402, 'received': 1403, 'fallen': 1404, 'robbery': 1405, 'record': 1406, 'sinister': 1407, 'foresight': 1408, 'guard': 1409, 'discoloured': 1410, 'undoubtedly': 1411, 'ones': 1412, 'endeavoured': 1413, 'lonely': 1414, 'eventually': 1415, 'laying': 1416, 'bridge': 1417, 'savannah': 1418, 'grief': 1419, 'bar': 1420, 'upper': 1421, 'dimly': 1422, 'breath': 1423, 'distinctly': 1424, 'dogcart': 1425, 'deserted': 1426, 'human': 1427, 'solution': 1428, 'christmas': 1429, 'peterson': 1430, 'henry': 1431, 'hung': 1432, 'carbuncle': 1433, 'reward': 1434, '1000': 1435, 'bureau': 1436, 'refused': 1437, 'inn': 1438, 'breckinridge': 1439, '‘but': 1440, 'capital': 1441, 'village': 1442, 'match': 1443, 'fastened': 1444, 'dangerous': 1445, 'bellrope': 1446, 'lysander': 1447, 'due': 1448, 'fuller’searth': 1449, 'affair': 1450, 'robert': 1451, 'scandal': 1452, 'emotion': 1453, 'lately': 1454, 'rise': 1455, 'sufficient': 1456, 'fierce': 1457, 'attracted': 1458, 'powers': 1459, 'clearing': 1460, 'incidents': 1461, 'sunk': 1462, 'chest': 1463, 'habit': 1464, 'pounds': 1465, 'hence': 1466, 'deduction': 1467, 'services': 1468, 'theories': 1469, 'endeavouring': 1470, 'companion’s': 1471, 'crown': 1472, 'stands': 1473, 'quarters': 1474, 'wheels': 1475, 'bit': 1476, 'promises': 1477, 'limbs': 1478, 'thrown': 1479, 'lined': 1480, 'delicacy': 1481, 'seriously': 1482, 'families': 1483, 'closing': 1484, 'energetic': 1485, 'agitation': 1486, 'gesture': 1487, 'delicate': 1488, 'putting': 1489, 'living': 1490, 'avenue': 1491, 'rolled': 1492, 'subtle': 1493, 'methods': 1494, 'listen': 1495, 'lives': 1496, 'temple': 1497, 'advantages': 1498, 'driven': 1499, 'lawyer': 1500, 'repeated': 1501, 'earnestly': 1502, 'glimpse': 1503, 'signal': 1504, 'occupant': 1505, 'weapon': 1506, 'size': 1507, 'capable': 1508, 'quarrel': 1509, 'crowd': 1510, 'watched': 1511, 'hurt': 1512, 'brave': 1513, 'breathing': 1514, 'draw': 1515, 'rushing': 1516, 'advantage': 1517, 'nerves': 1518, 'attempt': 1519, 'quest': 1520, 'satisfaction': 1521, 'prompt': 1522, 'staring': 1523, 'slept': 1524, 'coffee': 1525, 'named': 1526, 'loves': 1527, 'midnight': 1528, 'loved': 1529, 'snake': 1530, 'chronicle': 1531, 'liberty': 1532, 'rule': 1533, 'occur': 1534, 'wrinkled': 1535, 'gain': 1536, 'british': 1537, 'altogether': 1538, 'noticed': 1539, 'especially': 1540, 'indicated': 1541, 'china': 1542, 'clever': 1543, 'column': 1544, 'purely': 1545, 'fourteen': 1546, '‘tell': 1547, 'showing': 1548, 'particulars': 1549, 'gentlemen': 1550, 'north': 1551, 'south': 1552, 'getting': 1553, 'fill': 1554, 'recall': 1555, 'disappointment': 1556, 'me’': 1557, 'knowing': 1558, 'ink': 1559, 'fairly': 1560, 'shut': 1561, '9': 1562, 'laugh': 1563, 'wouldn’t': 1564, 'post': 1565, 'concerned': 1566, 'questions': 1567, 'asleep': 1568, 'lunch': 1569, 'houses': 1570, 'fourth': 1571, 'gently': 1572, 'energy': 1573, 'game': 1574, 'wild': 1575, 'confidence': 1576, 'correct': 1577, 'corridor': 1578, 'massive': 1579, 'gate': 1580, 'gazed': 1581, 'striking': 1582, 'success': 1583, 'escape': 1584, 'criminals': 1585, 'stand': 1586, 'distinguish': 1587, 'deeper': 1588, 'warning': 1589, 'peeped': 1590, 'presently': 1591, 'motive': 1592, 'tangled': 1593, 'fly': 1594, 'confessed': 1595, 'picked': 1596, 'drink': 1597, 'teeth': 1598, 'de': 1599, 'trying': 1600, 'tottenham': 1601, 'income': 1602, 'stock': 1603, 'paying': 1604, 'extremely': 1605, 'flush': 1606, 'fringe': 1607, 'remembered': 1608, 'drawer': 1609, 'leadenhall': 1610, 'swear': 1611, 'talked': 1612, 'unforeseen': 1613, 'bundle': 1614, 'directed': 1615, 'leaned': 1616, 'sleeves': 1617, 'gather': 1618, 'leaves': 1619, 'similar': 1620, 'instead': 1621, 'lower': 1622, 'pen': 1623, 'tinted': 1624, 'settle': 1625, 'lady’s': 1626, 'shelf': 1627, 'reasons': 1628, 'assured': 1629, 'connected': 1630, 'free': 1631, 'chemical': 1632, 'reply': 1633, 'master': 1634, 'misfortune': 1635, 'man’s': 1636, 'solve': 1637, 'brow': 1638, 'utterly': 1639, 'older': 1640, 'recovered': 1641, 'seated': 1642, 'aid': 1643, 'onto': 1644, 'hurry': 1645, 'gamekeeper': 1646, 'states': 1647, 'excited': 1648, 'blunt': 1649, 'lies': 1650, 'confession': 1651, 'bristol': 1652, 'rapidly': 1653, 'meaning': 1654, 'reference': 1655, 'approach': 1656, 'sky': 1657, 'bless': 1658, 'absurd': 1659, 'brother': 1660, 'averse': 1661, 'shattered': 1662, 'ashamed': 1663, 'continually': 1664, 'interview': 1665, 'health': 1666, 'mistaken': 1667, 'failed': 1668, 'animal': 1669, 'stop': 1670, 'definite': 1671, 'trace': 1672, 'tracks': 1673, 'visible': 1674, 'dust': 1675, 'meant': 1676, 'folded': 1677, 'weight': 1678, 'deduced': 1679, 'cord': 1680, 'acting': 1681, 'foul': 1682, 'cover': 1683, 'skill': 1684, 'club': 1685, 'adventures': 1686, 'latter': 1687, 'conjecture': 1688, 'tapping': 1689, 'arm': 1690, 'owe': 1691, 'generally': 1692, 'reported': 1693, 'war': 1694, 'leaving': 1695, 'servants': 1696, 'curiosity': 1697, 'protruding': 1698, 'empty': 1699, 'southern': 1700, 'beginning': 1701, 'notice': 1702, 'unable': 1703, 'detail': 1704, 'hudson': 1705, 'visited': 1706, 'described': 1707, 'pressing': 1708, 'screamed': 1709, 'greater': 1710, 'art': 1711, 'charming': 1712, 'pondicherry': 1713, 'quickly': 1714, 'page': 1715, 'weather': 1716, 'proved': 1717, 'darkness': 1718, 'calling': 1719, 'touched': 1720, 'swinging': 1721, 'whitney': 1722, 'sweet': 1723, 'doubtless': 1724, 'promised': 1725, 'swandam': 1726, 'opium': 1727, 'poison': 1728, 'muttered': 1729, 'thoughts': 1730, 'forget': 1731, 'horse': 1732, 'sombre': 1733, 'bricks': 1734, 'proceed': 1735, 'garments': 1736, 'scar': 1737, 'swept': 1738, 'frightened': 1739, 'sleep': 1740, 'crossed': 1741, 'sharply': 1742, 'barred': 1743, 'whitewashed': 1744, 'goodness': 1745, 'lip': 1746, 'scream': 1747, 'committed': 1748, 'paid': 1749, 'handed': 1750, 'places': 1751, 'unnecessary': 1752, 'gas': 1753, 'sold': 1754, 'kitchen': 1755, 'offered': 1756, 'thousand': 1757, 'jewelcase': 1758, 'jewel': 1759, 'agency': 1760, 'examine': 1761, 'nose': 1762, 'giving': 1763, 'hearty': 1764, 'salesman': 1765, 'nodded': 1766, 'unlocked': 1767, 'grimesby': 1768, 'berkshire': 1769, 'dragged': 1770, 'advance': 1771, 'accident': 1772, 'temper': 1773, 'accept': 1774, '‘very': 1775, 'moments': 1776, 'security': 1777, 'forth': 1778, 'dressinggown': 1779, 'metallic': 1780, 'sun': 1781, 'joy': 1782, 'roylott’s': 1783, 'common': 1784, 'assure': 1785, 'shoes': 1786, '‘we': 1787, 'inconvenience': 1788, 'fee': 1789, 'unpleasant': 1790, 'aloysius': 1791, 'missing': 1792, 'friendly': 1793, 'acted': 1794, 'burnwell': 1795, 'task': 1796, 'niece': 1797, 'stoper': 1798, 'drunk': 1799, 'keys': 1800, 'rucastles': 1801, '8': 1802, '5': 1803, '6': 1804, 'precise': 1805, 'admirably': 1806, 'lover': 1807, 'sneer': 1808, 'drawing': 1809, 'motives': 1810, 'reasoner': 1811, 'observation': 1812, 'reigning': 1813, 'wet': 1814, 'burned': 1815, 'fail': 1816, 'parallel': 1817, 'carelessly': 1818, 'mud': 1819, 'vile': 1820, 'particularly': 1821, 'forefinger': 1822, 'member': 1823, 'baffled': 1824, 'cigarette': 1825, 'trifling': 1826, 'europe': 1827, 'twist': 1828, 'bought': 1829, 'wearing': 1830, 'brougham': 1831, 'guineas': 1832, 'apiece': 1833, 'slow': 1834, 'paused': 1835, 'immediately': 1836, 'beryl': 1837, 'extended': 1838, 'broadbrimmed': 1839, 'mask': 1840, 'apparently': 1841, 'count': 1842, 'von': 1843, 'discretion': 1844, 'wishes': 1845, 'exactly': 1846, 'lounging': 1847, 'impatiently': 1848, 'advise': 1849, 'uncontrollable': 1850, 'hurled': 1851, 'monograph': 1852, 'produce': 1853, 'landlady': 1854, 'informed': 1855, 'enter': 1856, 'respectable': 1857, 'choked': 1858, 'obliged': 1859, 'helpless': 1860, 'funny': 1861, 'ended': 1862, 'preposterous': 1863, 'closely': 1864, 'lounged': 1865, 'runs': 1866, 'godfrey': 1867, 'mistress': 1868, 'keeping': 1869, 'tie': 1870, 'john’': 1871, 'jumped': 1872, 'minutes’': 1873, 'altar': 1874, 'driving': 1875, 'beer': 1876, 'busy': 1877, 'discuss': 1878, 'cap': 1879, 'amiable': 1880, 'peering': 1881, 'costume': 1882, 'guardsmen': 1883, 'cigars': 1884, 'carries': 1885, 'orders': 1886, 'solemnly': 1887, 'borne': 1888, 'principal': 1889, 'proceedings': 1890, 'playing': 1891, 'injured': 1892, 'slipping': 1893, 'nicely': 1894, 'everyone': 1895, 'row': 1896, 'palm': 1897, 'thinks': 1898, 'instinct': 1899, 'rush': 1900, 'steel': 1901, 'hurriedly': 1902, 'completely': 1903, 'trained': 1904, 'peace': 1905, 'threatened': 1906, 'merry': 1907, 'greeting': 1908, 'custom': 1909, 'routine': 1910, 'effects': 1911, 'daring': 1912, 'begin': 1913, 'unique': 1914, 'larger': 1915, 'instance': 1916, 'guide': 1917, 'pride': 1918, 'average': 1919, 'overcoat': 1920, 'worked': 1921, 'forgot': 1922, 'becomes': 1923, 'suffer': 1924, 'pope’s': 1925, 'fortunes': 1926, 'forehead': 1927, 'spaulding': 1928, 'price': 1929, 'pictures': 1930, 'it’': 1931, '‘well’': 1932, 'sympathy': 1933, '‘not': 1934, 'cared': 1935, 'willing': 1936, '‘this': 1937, 'cocked': 1938, 'tugged': 1939, '‘dear': 1940, 'gravely': 1941, 'conditions': 1942, 'belief': 1943, 'anyhow': 1944, 'delight': 1945, 'risk': 1946, 'consideration': 1947, 'risen': 1948, 'using': 1949, 'moved': 1950, 'grave': 1951, 'personally': 1952, 'richer': 1953, 'expensive': 1954, 'thirty': 1955, 'bill': 1956, 'travelled': 1957, 'lines': 1958, 'enclosure': 1959, 'vigorously': 1960, 'cleanshaven': 1961, 'beat': 1962, 'hurrying': 1963, 'newspaper': 1964, 'shop': 1965, 'block': 1966, 'cup': 1967, 'clients': 1968, 'wrapped': 1969, 'extreme': 1970, 'reaction': 1971, 'brilliant': 1972, 'expedition': 1973, 'entering': 1974, 'hunting': 1975, 'wonderful': 1976, 'treasure': 1977, 'murderer': 1978, 'thief': 1979, 'director': 1980, 'minutely': 1981, 'sooner': 1982, 'occasion': 1983, 'reserve': 1984, 'arranged': 1985, 'pitch': 1986, 'tension': 1987, 'protruded': 1988, 'aperture': 1989, 'rested': 1990, 'jump': 1991, 'clutched': 1992, 'blandly': 1993, 'pal': 1994, 'method': 1995, 'absence': 1996, 'guess': 1997, 'vanishing': 1998, 'beating': 1999, 'rang': 2000, 'stained': 2001, 'premises': 2002, 'removed': 2003, 'existence': 2004, 'leading': 2005, 'unnatural': 2006, 'test': 2007, 'dull': 2008, 'feather': 2009, 'communication': 2010, 'realising': 2011, 'you’ve': 2012, 'harm': 2013, 'sell': 2014, 'separate': 2015, 'jacket': 2016, 'visitors': 2017, 'weak': 2018, 'independent': 2019, 'advertised': 2020, 'book': 2021, 'faith': 2022, 'pressed': 2023, 'upward': 2024, 'describe': 2025, 'hanging': 2026, 'clapped': 2027, 'softly': 2028, 'knee': 2029, 'material': 2030, 'wrist': 2031, 'buttoned': 2032, 'neatly': 2033, 'fully': 2034, 'torn': 2035, 'strongly': 2036, 'relatives': 2037, 'solid': 2038, 'puffing': 2039, 'girl’s': 2040, 'expense': 2041, 'succeed': 2042, 'delighted': 2043, 'characteristics': 2044, 'rat': 2045, 'moisture': 2046, 'crushed': 2047, 'mantelpiece': 2048, 'effort': 2049, 'personal': 2050, 'increased': 2051, 'forever': 2052, 'dramatic': 2053, 'fate': 2054, 'whip': 2055, 'respects': 2056, 'disguise': 2057, 'recognise': 2058, 'whiskers': 2059, 'request': 2060, 'telegram': 2061, 'camp': 2062, 'local': 2063, 'murder': 2064, 'largest': 2065, 'terms': 2066, 'mccarthys': 2067, 'june': 2068, 'actually': 2069, 'lodgekeeper': 2070, 'blows': 2071, 'wednesday': 2072, 'circumstantial': 2073, 'innocence': 2074, 'gained': 2075, 'perceive': 2076, 'guilty': 2077, 'gun': 2078, 'stated': 2079, 'hideous': 2080, 'aroused': 2081, 'disturbed': 2082, '‘do': 2083, 'cloth': 2084, 'newspapers': 2085, 'lovely': 2086, 'parted': 2087, 'excitement': 2088, 'forming': 2089, 'victoria': 2090, 'prison': 2091, 'rattle': 2092, 'plot': 2093, 'wander': 2094, 'brains': 2095, '‘cooee’': 2096, 'rent': 2097, 'kindness': 2098, 'deductions': 2099, 'grasped': 2100, 'walls': 2101, 'blinds': 2102, 'measured': 2103, 'silently': 2104, 'woods': 2105, 'exact': 2106, 'bears': 2107, 'traced': 2108, 'wood': 2109, 'holding': 2110, 'lefthanded': 2111, 'indian': 2112, 'calmly': 2113, 'presumption': 2114, 'special': 2115, 'beard': 2116, 'avoid': 2117, 'weary': 2118, 'grip': 2119, 'companions': 2120, 'attacked': 2121, 'feature': 2122, 'policeman': 2123, 'mixed': 2124, 'judge': 2125, 'signed': 2126, 'logical': 2127, 'proof': 2128, 'furniture': 2129, 'deceased': 2130, 'exceptional': 2131, 'shriek': 2132, 'louder': 2133, 'chimney': 2134, 'fireplace': 2135, 'mother’s': 2136, 'clad': 2137, 'accused': 2138, 'plantation': 2139, 'trembling': 2140, 'ascended': 2141, 'burning': 2142, '‘to': 2143, 'devil': 2144, 'careful': 2145, 'uncle’s': 2146, '’85': 2147, 'newly': 2148, 'senseless': 2149, 'consciousness': 2150, 'unknown': 2151, 'jury': 2152, 'january': 2153, 'elapsed': 2154, 'shape': 2155, 'division': 2156, 'act': 2157, 'relations': 2158, 'necessary': 2159, 'readily': 2160, 'ship': 2161, 'dundee': 2162, 'sailingship': 2163, 'initials': 2164, 'efforts': 2165, 'dim': 2166, 'sallow': 2167, 'decoyed': 2168, 'escaped': 2169, 'hollow': 2170, 'lone': 2171, 'thirtysix': 2172, 'searched': 2173, 'dock': 2174, 'homeward': 2175, 'wave': 2176, 'george’s': 2177, 'flew': 2178, 'sleeping': 2179, 'pointing': 2180, 'glimmered': 2181, 'themselves': 2182, 'manager': 2183, 'midst': 2184, 'hour’s': 2185, 'clair’s': 2186, 'lee': 2187, 'regular': 2188, 'twinkled': 2189, 'plenty': 2190, 'fears': 2191, 'discovery': 2192, 'sill': 2193, 'boone': 2194, 'surrey': 2195, 'eager': 2196, 'associate': 2197, 'forgive': 2198, 'simply': 2199, 'rug': 2200, 'inquire': 2201, 'error': 2202, 'posted': 2203, 'valuable': 2204, 'shag': 2205, 'wake': 2206, 'summer': 2207, 'awake': 2208, 'bow': 2209, 'needed': 2210, 'panel': 2211, 'shirt': 2212, 'beauty': 2213, 'isn’t': 2214, 'exposure': 2215, 'chosen': 2216, 'watching': 2217, 'fat': 2218, 'roughs': 2219, 'ruefully': 2220, 'distinct': 2221, 'loop': 2222, 'precaution': 2223, 'replace': 2224, 'gathered': 2225, 'indoors': 2226, 'freely': 2227, 'buy': 2228, 'recalled': 2229, 'swung': 2230, 'alpha': 2231, 'stall': 2232, 'warm': 2233, 'fowls': 2234, 'oakshott': 2235, 'brixton': 2236, 'egg': 2237, 'what’s': 2238, 'speedily': 2239, 'wealth': 2240, 'god’s': 2241, 'big': 2242, 'rumours': 2243, 'knock': 2244, 'ladies': 2245, 'communicate': 2246, 'intimate': 2247, 'approaching': 2248, 'wandering': 2249, 'harrow': 2250, 'wing': 2251, 'shrieked': 2252, 'throat': 2253, 'move': 2254, 'clang': 2255, 'gaiters': 2256, 'poker': 2257, 'fields': 2258, 'boards': 2259, 'dated': 2260, 'examining': 2261, 'permission': 2262, 'lash': 2263, 'essential': 2264, 'clearer': 2265, 'command': 2266, 'huge': 2267, 'clump': 2268, 'cast': 2269, 'occasional': 2270, 'clock': 2271, 'soothing': 2272, 'causing': 2273, 'murderous': 2274, 'composed': 2275, '‘mr': 2276, 'hydraulic': 2277, 'eyford': 2278, '‘quite': 2279, 'thus': 2280, 'unfortunately': 2281, 'supper': 2282, 'fiftyguinea': 2283, 'ferguson': 2284, 'moonlight': 2285, 'gasped': 2286, 'justice': 2287, 'stretching': 2288, 'announced': 2289, 'vanish': 2290, 'ceremony': 2291, 'disturbance': 2292, 'millar': 2293, 'bouquet': 2294, 'pew': 2295, 'bride’s': 2296, 'you’re': 2297, 'allowance': 2298, 'francis': 2299, 'moulton': 2300, 'somewhere': 2301, 'conduct': 2302, 'bear': 2303, 'beryls': 2304, 'lucy': 2305, 'moving': 2306, 'rage': 2307, 'concealed': 2308, 'dressingroom': 2309, 'tradesmen’s': 2310, 'stable': 2311, 'halfpast': 2312, 'sole': 2313, 'employer': 2314, 'suite': 2315, 'skylight': 2316, 'fowler': 2317, 'mention': 2318, 'akin': 2319, 'perfect': 2320, 'false': 2321, 'admirable': 2322, 'men’s': 2323, 'admit': 2324, 'adjusted': 2325, 'introduce': 2326, 'factor': 2327, 'crack': 2328, 'questionable': 2329, 'interests': 2330, 'drug': 2331, 'clues': 2332, 'mysteries': 2333, 'abandoned': 2334, 'summons': 2335, 'tragedy': 2336, 'mission': 2337, 'accomplished': 2338, 'holland': 2339, 'daily': 2340, 'night—it': 2341, 'associated': 2342, 'blind': 2343, 'pacing': 2344, 'mood': 2345, 'introspective': 2346, 'suits': 2347, 'thursday': 2348, 'rubbed': 2349, 'scored': 2350, 'cuts': 2351, 'scraped': 2352, 'specimen': 2353, 'walks': 2354, 'pronounce': 2355, 'active': 2356, 'process': 2357, 'lighting': 2358, 'hundreds': 2359, 'notepaper': 2360, 'desires': 2361, 'deepest': 2362, 'presumably': 2363, 'packet': 2364, 'woven': 2365, 'shelves': 2366, 'sparkled': 2367, 'discover': 2368, 'bohemian': 2369, 'taste': 2370, 'bands': 2371, 'flamecoloured': 2372, 'secured': 2373, 'halfway': 2374, 'fur': 2375, 'resolution': 2376, 'title': 2377, 'grow': 2378, 'incisive': 2379, 'condescend': 2380, 'grand': 2381, 'hereditary': 2382, 'briefly': 2383, 'born': 2384, 'entangled': 2385, 'compromising': 2386, 'legal': 2387, 'purposes': 2388, 'pooh': 2389, 'strict': 2390, 'threatens': 2391, 'carte': 2392, 'leather': 2393, 'serpentine': 2394, 'royal': 2395, 'chat': 2396, 'surrounded': 2397, 'crimes': 2398, 'grasp': 2399, 'possibility': 2400, 'failing': 2401, 'disreputable': 2402, 'limp': 2403, 'villa': 2404, 'stories': 2405, 'ostlers': 2406, 'rubbing': 2407, 'exchange': 2408, 'bonnet': 2409, 'returns': 2410, 'plan': 2411, 'sounded': 2412, 'ominous': 2413, 'former': 2414, 'transferred': 2415, 'issue': 2416, 'gentleman’s': 2417, 'chambers': 2418, 'handsome': 2419, 'aquiline': 2420, 'brushed': 2421, 'waving': 2422, 'edgeware': 2423, 'halfbuttoned': 2424, 'sticking': 2425, 'die': 2426, 'driver': 2427, 'fare': 2428, 'sovereign': 2429, 'twentyfive': 2430, 'fast': 2431, '‘thank': 2432, '‘come': 2433, 'bachelor': 2434, 'unexpected': 2435, 'separated': 2436, 'beef': 2437, 'provided': 2438, 'confined': 2439, 'baggy': 2440, 'lamps': 2441, 'remarkably': 2442, 'animated': 2443, 'scissorsgrinder': 2444, 'welldressed': 2445, 'chances': 2446, 'political': 2447, 'pshaw': 2448, 'gleam': 2449, 'sidelights': 2450, 'smart': 2451, 'loafer': 2452, 'sides': 2453, 'knot': 2454, 'savagely': 2455, 'protect': 2456, 'crowded': 2457, 'hadn’t': 2458, 'compunction': 2459, 'grace': 2460, 'injuring': 2461, 'couch': 2462, 'rocket': 2463, 'curled': 2464, 'shouting': 2465, 'guessed': 2466, 'piteous': 2467, 'spectacle': 2468, 'allimportant': 2469, 'overpowering': 2470, 'impulse': 2471, 'baby': 2472, 'shake': 2473, 'bellpull': 2474, 'hesitated': 2475, 'safer': 2476, 'practically': 2477, 'searching': 2478, 'mister': 2479, 'slim': 2480, 'eagerly': 2481, 'descended': 2482, 'hopes': 2483, 'drawingroom': 2484, 'tore': 2485, 'esq': 2486, 'employed': 2487, 'male': 2488, 'resource': 2489, 'wronged': 2490, 'possess': 2491, 'truly': 2492, 'epistle': 2493, 'level': 2494, 'coldly': 2495, 'immensely': 2496, 'indebted': 2497, 'observing': 2498, 'wit': 2499, 'elderly': 2500, 'intrusion': 2501, 'abruptly': 2502, 'utmost': 2503, 'smaller': 2504, 'positive': 2505, 'puffed': 2506, 'indications': 2507, 'albert': 2508, 'dangling': 2509, 'velvet': 2510, 'occupation': 2511, 'snuff': 2512, 'insult': 2513, 'telling': 2514, 'literature': 2515, 'trick': 2516, 'addition': 2517, 'ezekiah': 2518, 'hopkins': 2519, '7': 2520, 'april': 2521, '27': 2522, 'coburg': 2523, 'job': 2524, 'wages': 2525, 'vincent': 2526, 'ideas': 2527, 'employers': 2528, 'faults': 2529, 'keeps': 2530, 'that’': 2531, 'here’s': 2532, '‘have': 2533, 'one’s': 2534, 'millionaire': 2535, 'enormous': 2536, 'instructions': 2537, 'think’': 2538, 'grown': 2539, 'holiday': 2540, 'brick': 2541, 'wilson’': 2542, 'warmly': 2543, 'disgust': 2544, 'fund': 2545, 'spread': 2546, 'lengthened': 2547, '‘in': 2548, 'awkward': 2549, 'pawnbroker’s': 2550, 'mostly': 2551, 'well’': 2552, '‘it’s': 2553, 'copy': 2554, 'britannica': 2555, 'volume': 2556, 'persuaded': 2557, 'reasoned': 2558, 'sheets': 2559, 'golden': 2560, 'cardboard': 2561, 'announcement': 2562, 'comical': 2563, 'roots': 2564, 'landlord': 2565, '‘oh’': 2566, 'william': 2567, 'morris': 2568, 'convenience': 2569, 'edward': 2570, 'wisely': 2571, 'joke': 2572, 'pick': 2573, 'sinking': 2574, 'complain': 2575, 'frankly': 2576, 'bizarre': 2577, 'mysterious': 2578, 'proves': 2579, 'nodding': 2580, 'james’s': 2581, 'music': 2582, 'twostoried': 2583, 'laurel': 2584, 'bushes': 2585, 'brightly': 2586, 'judgment': 2587, 'wilson’s': 2588, 'enemy’s': 2589, 'picture': 2590, 'traffic': 2591, 'stream': 2592, 'branch': 2593, 'suburban': 2594, 'play': 2595, 'enthusiastic': 2596, 'stalls': 2597, 'alternately': 2598, 'swing': 2599, 'lust': 2600, 'intuition': 2601, 'dense': 2602, 'nocturnal': 2603, 'despair': 2604, 'quarterpast': 2605, 'oxford': 2606, 'sadfaced': 2607, 'shiny': 2608, 'buttoning': 2609, 'crop': 2610, 'chase': 2611, 'wants': 2612, 'deference': 2613, 'saturday': 2614, 'higher': 2615, '30000': 2616, 'grandfather': 2617, 'raising': 2618, 'turns': 2619, 'endless': 2620, 'labyrinth': 2621, 'imbecile': 2622, 'claws': 2623, 'thoroughfare': 2624, 'cabs': 2625, 'solemn': 2626, 'perched': 2627, 'chairman': 2628, 'warnings': 2629, 'borrowed': 2630, 'napoleons': 2631, 'contains': 2632, 'packed': 2633, 'directors': 2634, 'choose': 2635, 'flash': 2636, 'holes': 2637, 'bulky': 2638, 'spark': 2639, 'womanly': 2640, 'chink': 2641, 'momentary': 2642, 'streamed': 2643, 'shock': 2644, 'compliment': 2645, 'clattered': 2646, 'wrists': 2647, 'hearing': 2648, 'whisky': 2649, 'soda': 2650, 'rogue': 2651, 'vulgar': 2652, 'tunnel': 2653, 'ascertaining': 2654, 'remaining': 2655, 'completed': 2656, 'beautifully': 2657, 'exclaimed': 2658, 'commonplaces': 2659, 'benefactor': 2660, 'c’est': 2661, 'invent': 2662, 'roofs': 2663, 'outré': 2664, 'foreseen': 2665, 'magistrate': 2666, 'depend': 2667, 'smiled': 2668, 'contact': 2669, 'husband’s': 2670, 'cruelty': 2671, 'happens': 2672, 'lid': 2673, 'served': 2674, 'charm': 2675, 'simpler': 2676, 'presents': 2677, 'glove': 2678, 'buttons': 2679, 'symptoms': 2680, 'tap': 2681, 'announce': 2682, 'purport': 2683, 'bang': 2684, 'fifteen': 2685, 'younger': 2686, 'hardy': 2687, 'foreman': 2688, 'traveller': 2689, 'impatient': 2690, 'travel': 2691, 'indulge': 2692, 'earn': 2693, 'typewriting': 2694, 'stole': 2695, 'annoyed': 2696, 'ball': 2697, 'cashier': 2698, 'fond': 2699, 'plain': 2700, 'testament': 2701, 'cross': 2702, 'hansom': 2703, 'stepped': 2704, 'fourwheeler': 2705, 'cabman': 2706, 'pledge': 2707, 'sob': 2708, 'westhouse': 2709, 'marbank': 2710, 'fenchurch': 2711, 'sealed': 2712, 'maiden': 2713, 'realise': 2714, 'darker': 2715, 'gloves': 2716, 'greyish': 2717, 'comfortable': 2718, '’pon': 2719, 'hit': 2720, 'sleeve': 2721, 'noted': 2722, 'violet': 2723, 'printed': 2724, 'built': 2725, 'moustache': 2726, 'faced': 2727, 'elasticsided': 2728, 'answers': 2729, 'treated': 2730, 'scarlet': 2731, 'sufferer': 2732, 'spring': 2733, 'bottles': 2734, 'middlesized': 2735, 'insinuating': 2736, 'goodevening': 2737, 'linen': 2738, 'controlled': 2739, 'abroad': 2740, 'discovering': 2741, 'individuality': 2742, 'handwriting': 2743, 'correspondence': 2744, 'typewriter': 2745, 'magnifying': 2746, 'stepping': 2747, 'collapsed': 2748, 'cruel': 2749, 'huddled': 2750, 'preserve': 2751, 'affectionate': 2752, 'evident': 2753, 'forbidding': 2754, 'insisted': 2755, 'groaned': 2756, 'decidedly': 2757, 'flattered': 2758, 'attentions': 2759, 'produced': 2760, 'engagement': 2761, 'vows': 2762, 'ought': 2763, 'punishment': 2764, 'bitter': 2765, 'treat': 2766, 'scoundrel': 2767, 'revealed': 2768, 'characteristic': 2769, 'ungrateful': 2770, 'rattling': 2771, 'platform': 2772, 'gaunt': 2773, 'difference': 2774, 'intervals': 2775, 'tossed': 2776, 'sounds': 2777, 'conjectured': 2778, 'opportunity': 2779, 'district': 2780, 'proprietor': 2781, 'colonies': 2782, 'neighbouring': 2783, '3rd': 2784, 'lake': 2785, 'mentioned': 2786, 'patience': 2787, 'quarrelling': 2788, 'damning': 2789, 'culprit': 2790, 'confirm': 2791, 'righthand': 2792, 'shave': 2793, 'satisfied': 2794, 'service': 2795, 'minor': 2796, 'inquest': 2797, 'arrest': 2798, 'indignation': 2799, 'highly': 2800, 'forgotten': 2801, 'according': 2802, 'displayed': 2803, 'turner’s': 2804, 'manners': 2805, 'enemies': 2806, 'final': 2807, '‘how': 2808, '‘a': 2809, 'concluded': 2810, 'severe': 2811, 'strongest': 2812, 'hypothesis': 2813, 'hereford': 2814, 'refuse': 2815, 'pink': 2816, 'flaw': 2817, 'quarrels': 2818, 'dad': 2819, 'groping': 2820, 'hellish': 2821, 'bone': 2822, 'extent': 2823, 'paces': 2824, 'mccarthy’s': 2825, 'staying': 2826, 'screening': 2827, 'admire': 2828, 'hangs': 2829, 'tale': 2830, 'barmaid': 2831, 'accounts': 2832, 'murdered': 2833, 'cloudless': 2834, 'add': 2835, 'heiress': 2836, 'cocksure': 2837, 'flying': 2838, 'replied': 2839, 'merest': 2840, 'moonshine': 2841, 'fog': 2842, 'widespread': 2843, 'blotches': 2844, 'stricken': 2845, 'son’s': 2846, 'desired': 2847, 'brows': 2848, 'downward': 2849, 'compressed': 2850, 'whipcord': 2851, 'snarl': 2852, 'damp': 2853, 'situated': 2854, 'wealthy': 2855, 'belt': 2856, 'reeds': 2857, 'spot': 2858, 'trampled': 2859, 'waterproof': 2860, 'heels': 2861, 'tiptoes': 2862, 'tree': 2863, 'dried': 2864, 'bark': 2865, 'highroad': 2866, 'regained': 2867, 'growing': 2868, 'injuries': 2869, 'cloak': 2870, 'smokes': 2871, 'leg': 2872, 'considering': 2873, 'australian': 2874, 'map': 2875, 'wired': 2876, 'ballarat': 2877, 'surgeon': 2878, 'ash': 2879, 'possessed': 2880, 'grizzled': 2881, 'outstanding': 2882, 'eyebrows': 2883, 'dignity': 2884, 'corners': 2885, 'answering': 2886, 'reckless': 2887, 'killed': 2888, 'braved': 2889, 'tongue': 2890, 'exposed': 2891, 'deed': 2892, 'objections': 2893, 'happily': 2894, 'publicity': 2895, 'analytical': 2896, 'ending': 2897, 'explanations': 2898, 'surmise': 2899, 'retain': 2900, 'barque': 2901, 'sketch': 2902, 'date': 2903, 'beaten': 2904, 'storm': 2905, 'gale': 2906, 'newcomer': 2907, 'umbrella': 2908, 'weighed': 2909, 'inexplicable': 2910, 'commencement': 2911, 'elias': 2912, 'florida': 2913, '1869': 2914, 'republican': 2915, 'smoked': 2916, 'begged': 2917, 'lumberroom': 2918, 'plate': 2919, 'postmark': 2920, 'sins': 2921, 'palpitating': 2922, 'scrawled': 2923, 'flap': 2924, 'belonged': 2925, 'brass': 2926, '‘they': 2927, 'fluffy': 2928, 'ashes': 2929, 'dread': 2930, 'screaming': 2931, 'fits': 2932, 'eccentricity': 2933, 'attic': 2934, 'contents': 2935, 'destroyed': 2936, 'repute': 2937, 'politics': 2938, '’84': 2939, 'outstretched': 2940, '‘put': 2941, 'sundial’': 2942, 'sundial': 2943, '‘some': 2944, 'vain': 2945, 'hesitation': 2946, 'troubles': 2947, 'begun': 2948, 'message': 2949, 'writhing': 2950, 'deaths': 2951, '4th': 2952, 'mccauley': 2953, 'paramore': 2954, '9th': 2955, 'safety': 2956, 'perils': 2957, 'unhappy': 2958, 'observer': 2959, 'series': 2960, 'attain': 2961, 'senses': 2962, 'profound': 2963, 'regards': 2964, 'eccentric': 2965, 'cocaine': 2966, 'main': 2967, 'item': 2968, 'assume': 2969, 'writer': 2970, 'starting': 2971, 'urged': 2972, 'individual': 2973, 'bending': 2974, 'klux': 2975, 'derived': 2976, 'civil': 2977, 'openly': 2978, 'organisation': 2979, 'government': 2980, 'movement': 2981, 'implicate': 2982, 'entries': 2983, 'miserable': 2984, 'commence': 2985, 'lifted': 2986, 'residence': 2987, 'haste': 2988, 'victim': 2989, 'riverside': 2990, 'hurts': 2991, 'hungry': 2992, 'bite': 2993, 'cupboard': 2994, 'addressed': 2995, 'gang': 2996, 'february': 2997, 'badly': 2998, 'isa': 2999, 'college': 3000, 'drenched': 3001, 'pity': 3002, 'drooping': 3003, 'lids': 3004, 'losing': 3005, 'selfcontrol': 3006, 'pulling': 3007, 'kate': 3008, 'pluck': 3009, 'escort': 3010, 'errand': 3011, 'river': 3012, 'monotonous': 3013, 'attendant': 3014, 'supply': 3015, 'exclamation': 3016, 'haggard': 3017, 'nerve': 3018, 'frighten': 3019, 'lot': 3020, 'favoured': 3021, 'hoped': 3022, 'wharf': 3023, 'ay': 3024, 'trusty': 3025, 'cedars': 3026, 'doublebedded': 3027, 'succession': 3028, 'gradually': 3029, 'invaluable': 3030, 'maybe': 3031, 'style': 3032, 'children': 3033, 'remarking': 3034, 'perform': 3035, 'fresno': 3036, 'proceeded': 3037, 'ejaculation': 3038, 'terribly': 3039, 'agitated': 3040, 'waved': 3041, 'constables': 3042, 'drops': 3043, 'threadneedle': 3044, 'lefthand': 3045, 'crosslegged': 3046, 'matches': 3047, 'penetrating': 3048, 'cripple': 3049, 'powerful': 3050, 'escorted': 3051, 'fault': 3052, 'stains': 3053, 'sink': 3054, 'throws': 3055, 'outskirts': 3056, 'hedge': 3057, 'villages': 3058, 'horse’s': 3059, 'colleague': 3060, 'stableboy': 3061, 'eagerness': 3062, 'lucky': 3063, 'diningroom': 3064, 'fainting': 3065, 'snatched': 3066, 'coarse': 3067, 'gravesend': 3068, 'pencil': 3069, 'certainty': 3070, 'conclusion': 3071, 'rearranging': 3072, 'insufficient': 3073, 'wandered': 3074, 'ounce': 3075, 'curling': 3076, 'stirring': 3077, 'previous': 3078, 'incredulity': 3079, 'coloured': 3080, 'repulsive': 3081, 'perpetual': 3082, 'needs': 3083, 'stooped': 3084, 'sponge': 3085, 'horrid': 3086, 'destiny': 3087, 'authorities': 3088, 'imprisonment': 3089, 'schoolmaster': 3090, 'articles': 3091, 'begging': 3092, 'fleshcoloured': 3093, 'wit’s': 3094, 'smearing': 3095, 'coppers': 3096, 'beggar': 3097, 'poured': 3098, 'identified': 3099, 'constable': 3100, 'hush': 3101, 'season': 3102, 'studied': 3103, 'worse': 3104, 'crackling': 3105, 'frost': 3106, 'whimsical': 3107, 'happen': 3108, 'goodge': 3109, 'lining': 3110, 'delay': 3111, 'joking': 3112, 'pierced': 3113, 'cracked': 3114, 'dusty': 3115, 'moral': 3116, 'degree': 3117, 'disregarding': 3118, 'limecream': 3119, 'improbable': 3120, 'capacity': 3121, 'decline': 3122, 'flat': 3123, 'silk': 3124, 'recently': 3125, 'candle': 3126, 'commissionaire': 3127, 'eh': 3128, 'radiance': 3129, 'mercy': 3130, '22nd': 3131, 'plumber': 3132, 'cosmopolitan': 3133, 'morcar': 3134, 'dressingtable': 3135, 'cusack': 3136, 'struggled': 3137, 'intense': 3138, 'policecourt': 3139, 'rifled': 3140, 'direct': 3141, 'advertising': 3142, 'robberies': 3143, 'determine': 3144, 'shillings': 3145, 'recovering': 3146, 'fitted': 3147, 'strode': 3148, 'suggest': 3149, 'dinner': 3150, 'stars': 3151, 'holborn': 3152, 'speaking': 3153, 'homely': 3154, 'establish': 3155, 'covent': 3156, 'recommended': 3157, 'birds': 3158, 'you’d': 3159, 'i’m': 3160, 'fiver': 3161, 'persuade': 3162, 'names': 3163, '117': 3164, 'nearing': 3165, 'overtook': 3166, 'verge': 3167, 'cheerily': 3168, 'basketchair': 3169, 'felony': 3170, 'link': 3171, 'crawl': 3172, 'thieves': 3173, 'kilburn': 3174, 'maggie’': 3175, 'tail': 3176, 'heaven': 3177, 'reaching': 3178, 'forgiveness': 3179, 'speckled': 3180, 'wellknown': 3181, 'roylotts': 3182, 'sharing': 3183, 'sleepy': 3184, 'investigations': 3185, 'admiring': 3186, 'submitted': 3187, 'terror': 3188, 'farintosh': 3189, 'helped': 3190, 'desk': 3191, 'alas': 3192, 'dangers': 3193, 'helen': 3194, 'survivor': 3195, 'gambler': 3196, 'acres': 3197, 'aristocratic': 3198, 'relative': 3199, 'sentence': 3200, 'india': 3201, 'resided': 3202, 'railway': 3203, 'obstacle': 3204, 'visits': 3205, 'disgraceful': 3206, 'correspondent': 3207, 'baboon': 3208, 'aunt': 3209, 'objection': 3210, 'fortnight': 3211, 'event': 3212, 'deprived': 3213, 'seared': 3214, 'inhabited': 3215, 'bedrooms': 3216, '‘certainly': 3217, 'nights': 3218, 'awakened': 3219, '‘ah': 3220, 'writhed': 3221, 'pain': 3222, 'oldfashioned': 3223, 'wide': 3224, 'cruelly': 3225, 'disturb': 3226, 'foolish': 3227, 'attend': 3228, 'whistles': 3229, 'falling': 3230, 'agricultural': 3231, 'investments': 3232, 'prices': 3233, 'fleecy': 3234, 'hedges': 3235, 'pleasant': 3236, 'contrast': 3237, 'tapped': 3238, 'shorter': 3239, 'gossip': 3240, 'goodafternoon': 3241, 'portion': 3242, 'wings': 3243, 'central': 3244, 'modern': 3245, 'belongs': 3246, 'slit': 3247, 'chairs': 3248, 'carpet': 3249, 'dummy': 3250, 'attached': 3251, 'rope': 3252, 'keenest': 3253, 'cat': 3254, 'cheetah': 3255, 'noise': 3256, 'manor': 3257, 'springing': 3258, 'chill': 3259, 'gaped': 3260, 'noiselessly': 3261, 'cane': 3262, 'darklantern': 3263, 'yelled': 3264, 'shutter': 3265, 'bare': 3266, 'slippers': 3267, 'length': 3268, 'terrified': 3269, 'shows': 3270, 'fangs': 3271, 'indirectly': 3272, 'responsible': 3273, 'finer': 3274, 'original': 3275, 'consultingroom': 3276, 'useless': 3277, 'bloodless': 3278, 'hardened': 3279, 'braced': 3280, 'cleaver': 3281, 'horrify': 3282, 'cleaned': 3283, 'equal': 3284, 'agony': 3285, 'genial': 3286, 'meal': 3287, 'finds': 3288, 'bones': 3289, 'brisk': 3290, '‘may': 3291, 'commission': 3292, '‘if': 3293, 'value’': 3294, 'night’s': 3295, 'deposit': 3296, 'ignorant': 3297, '‘ah’': 3298, 'gaze': 3299, 'astonished': 3300, 'winds': 3301, 'obeyed': 3302, 'rate': 3303, 'crisp': 3304, 'graveldrive': 3305, 'threshold': 3306, 'muttering': 3307, 'tone': 3308, 'pushing': 3309, 'uneasiness': 3310, 'stillness': 3311, 'preliminary': 3312, 'wrung': 3313, '‘for': 3314, 'shaken': 3315, 'declared': 3316, 'slammed': 3317, 'footsteps': 3318, 'newcomers': 3319, 'creases': 3320, 'introduced': 3321, 'green': 3322, 'ushered': 3323, 'columns': 3324, 'gigantic': 3325, 'pressure': 3326, 'engine': 3327, 'shapeless': 3328, 'implored': 3329, 'erect': 3330, 'moon': 3331, 'unconscious': 3332, 'dazed': 3333, 'etc': 3334, 'desperate': 3335, 'plainclothes': 3336, 'thanks': 3337, 'stationmaster': 3338, 'englishman': 3339, 'realised': 3340, 'perturbed': 3341, 'outhouse': 3342, 'soft': 3343, 'mould': 3344, 'persistence': 3345, 'lazily': 3346, 'fashionable': 3347, 'social': 3348, 'congratulate': 3349, 'cooperation': 3350, 'balmoral': 3351, 'san': 3352, 'francisco': 3353, 'hatty': 3354, 'figures': 3355, 'invited': 3356, 'floating': 3357, 'bride': 3358, 'prepared': 3359, 'prolonged': 3360, 'fortunately': 3361, 'ulster': 3362, 'jealousy': 3363, 'goodday': 3364, 'slang': 3365, 'doran’s': 3366, 'footing': 3367, 'lest': 3368, 'seek': 3369, 'convincing': 3370, 'dissatisfied': 3371, 'heaven’s': 3372, 'blowing': 3373, '6d': 3374, 'sherry': 3375, 'briskly': 3376, 'offended': 3377, 'pa': 3378, 'select': 3379, 'loving': 3380, 'snow': 3381, 'disgrace': 3382, 'banking': 3383, '‘one': 3384, 'magnificent': 3385, 'thirtynine': 3386, 'national': 3387, 'streatham': 3388, 'parr': 3389, 'spoiled': 3390, 'implore': 3391, '‘look': 3392, 'dad’': 3393, 'arthur’s': 3394, 'considered': 3395, 'complex': 3396, 'banker’s': 3397, 'accepted': 3398, 'entrance': 3399, 'footmarks': 3400, 'serve': 3401, 'sorrow': 3402, 'dearest': 3403, 'labour': 3404, 'debt': 3405, 'stealthily': 3406, 'opponent': 3407, 'impressions': 3408, 'prosecution': 3409, 'particular': 3410, 'sensationalism': 3411, 'erred': 3412, 'bordered': 3413, 'novel': 3414, 'governess': 3415, 'parents': 3416, 'favourably': 3417, 'governesses': 3418, 'fold': 3419, 'salary': 3420, 'offer': 3421, 'commands': 3422, '‘or': 3423, 'fancies': 3424, 'hunter’': 3425, 'cease': 3426, 'bradshaw': 3427, 'swan': 3428, 'buried': 3429, 'devised': 3430, 'unreasoning': 3431, 'planning': 3432, 'performance': 3433, 'impertinent': 3434, 'frightened’': 3435, 'loose': 3436, 'trunk': 3437, 'observant': 3438, 'jovial': 3439, 'ladder': 3440, 'rucastle’s': 3441, 'predominates': 3442, 'sex': 3443, 'emotions': 3444, 'abhorrent': 3445, 'softer': 3446, 'actions': 3447, 'intrusions': 3448, 'temperament': 3449, 'distracting': 3450, 'mental': 3451, 'instrument': 3452, 'disturbing': 3453, 'dubious': 3454, 'happiness': 3455, 'around': 3456, 'establishment': 3457, 'absorb': 3458, 'loathed': 3459, 'alternating': 3460, 'drowsiness': 3461, 'occupied': 3462, 'faculties': 3463, 'hopeless': 3464, 'odessa': 3465, 'atkinson': 3466, 'brothers': 3467, 'successfully': 3468, 'activity': 3469, 'shared': 3470, 'twentieth': 3471, '(for': 3472, 'brilliantly': 3473, 'attitude': 3474, 'dreams': 3475, 'scent': 3476, 'effusive': 3477, 'seldom': 3478, 'spirit': 3479, 'gasogene': 3480, 'wedlock': 3481, 'intended': 3482, 'centuries': 3483, 'jane': 3484, 'incorrigible': 3485, 'simplicity': 3486, 'shoe': 3487, 'firelight': 3488, 'crusted': 3489, 'malignant': 3490, 'bootslitting': 3491, 'slavey': 3492, 'iodoform': 3493, 'nitrate': 3494, 'bulge': 3495, 'secreted': 3496, 'stethoscope': 3497, 'ease': 3498, 'distinction': 3499, 'experiences': 3500, 'pinktinted': 3501, 'undated': 3502, 'insensibly': 3503, 'begins': 3504, 'imitate': 3505, 'processes': 3506, 'peculiar—that': 3507, 'texture': 3508, 'maker': 3509, '‘g’': 3510, '‘company’': 3511, '‘co’': 3512, '‘p’': 3513, '‘papier’': 3514, 'continental': 3515, 'gazetteer': 3516, 'eglow': 3517, 'eglonitz—here': 3518, 'egria': 3519, 'germanspeaking': 3520, 'country—in': 3521, 'carlsbad': 3522, 'glassfactories': 3523, 'papermills’': 3524, 'construction': 3525, 'sentence—‘this': 3526, 'received’': 3527, 'frenchman': 3528, 'russian': 3529, 'writes': 3530, 'prefers': 3531, 'curb': 3532, 'authoritative': 3533, 'richness': 3534, 'astrakhan': 3535, 'slashed': 3536, 'fronts': 3537, 'doublebreasted': 3538, 'brooch': 3539, 'calves': 3540, 'trimmed': 3541, 'tops': 3542, 'barbaric': 3543, 'opulence': 3544, 'extending': 3545, 'accent': 3546, 'binding': 3547, 'european': 3548, 'employs': 3549, 'quench': 3550, 'compromise': 3551, 'implicates': 3552, 'kings': 3553, 'apparent': 3554, 'reopened': 3555, 'desperation': 3556, 'addressing': 3557, 'wilhelm': 3558, 'gottsreich': 3559, 'ormstein': 3560, 'casselfelstein': 3561, 'prague': 3562, 'consulting': 3563, 'shutting': 3564, 'warsaw': 3565, 'index': 3566, 'paragraphs': 3567, 'concerning': 3568, 'biography': 3569, 'hebrew': 3570, 'rabbi': 3571, 'deepsea': 3572, 'contralto—hum': 3573, 'la': 3574, 'scala': 3575, 'prima': 3576, 'donna': 3577, 'imperial': 3578, 'opera': 3579, 'operatic': 3580, 'stage—ha': 3581, 'london—quite': 3582, 'blackmailing': 3583, 'compromised': 3584, 'prince': 3585, 'stolen': 3586, 'burglars': 3587, 'diverted': 3588, 'luggage': 3589, 'waylaid': 3590, 'propose': 3591, 'clotilde': 3592, 'lothman': 3593, 'saxemeningen': 3594, 'scandinavia': 3595, 'principles': 3596, 'resolute': 3597, 'lengths': 3598, 'betrothal': 3599, 'publicly': 3600, 'proclaimed': 3601, 'langham': 3602, 'chamois': 3603, 'scribbled': 3604, 'receipt': 3605, 'mademoiselle’s': 3606, 'john’s': 3607, 'awaiting': 3608, 'grim': 3609, 'exalted': 3610, 'apart': 3611, 'masterly': 3612, 'disentangled': 3613, 'invariable': 3614, 'illkempt': 3615, 'sidewhiskered': 3616, 'inflamed': 3617, 'amazing': 3618, 'disguises': 3619, 'tweedsuited': 3620, 'sequel': 3621, 'freemasonry': 3622, 'horsey': 3623, 'chubb': 3624, 'fasteners': 3625, 'mews': 3626, 'twopence': 3627, 'halfandhalf': 3628, 'fills': 3629, 'biographies': 3630, 'daintiest': 3631, 'planet': 3632, 'serpentinemews': 3633, 'sings': 3634, 'calls': 3635, 'confidant': 3636, 'depended': 3637, 'widened': 3638, 'balancing': 3639, 'moustached—evidently': 3640, 'excitedly': 3641, 'flurried': 3642, '‘drive': 3643, 'devil’': 3644, '‘first': 3645, 'hankey’s': 3646, 'regent': 3647, 'guinea': 3648, 'tags': 3649, 'harness': 3650, 'monica': 3651, 'monica’': 3652, 'cabby': 3653, 'surpliced': 3654, 'aisle': 3655, 'god’': 3656, '‘you’ll': 3657, 'halfdragged': 3658, 'mumbling': 3659, 'responses': 3660, 'vouching': 3661, 'tying': 3662, 'spinster': 3663, 'thanking': 3664, 'beamed': 3665, 'informality': 3666, 'license': 3667, 'sally': 3668, 'menaced': 3669, 'immediate': 3670, 'departure': 3671, 'measures': 3672, 'food': 3673, 'tray': 3674, 'hungrily': 3675, 'madame': 3676, 'unpleasantness': 3677, 'join': 3678, 'hand—so—you': 3679, 'roll': 3680, 'rejoin': 3681, 'neutral': 3682, 'role': 3683, 'simpleminded': 3684, 'nonconformist': 3685, 'benevolent': 3686, 'hare': 3687, 'equalled': 3688, 'vary': 3689, 'actor': 3690, 'science': 3691, 'acute': 3692, 'specialist': 3693, 'dusk': 3694, 'succinct': 3695, 'locality': 3696, 'shabbily': 3697, 'smoking': 3698, 'wheel': 3699, 'nursegirl': 3700, 'simplifies': 3701, 'doubleedged': 3702, 'princess': 3703, 'unlikely': 3704, 'concealment': 3705, 'secretive': 3706, 'secreting': 3707, 'guardianship': 3708, 'indirect': 3709, 'resolved': 3710, 'curve': 3711, 'elbowed': 3712, 'fists': 3713, 'loungers': 3714, 'scuffle': 3715, 'superb': 3716, 'purse': 3717, 'rough': 3718, 'conspiring': 3719, 'kindliness': 3720, 'smokerocket': 3721, 'ill—gentlemen': 3722, 'maids—joined': 3723, 'assuring': 3724, 'accomplice': 3725, 'suspected': 3726, 'compelled': 3727, 'grabs': 3728, 'unmarried': 3729, 'recess': 3730, 'sliding': 3731, 'replaced': 3732, 'coachman': 3733, 'overprecipitance': 3734, 'regain': 3735, 'deuce': 3736, 'grasping': 3737, 'impatience': 3738, 'simplify': 3739, 'majesty’s': 3740, 'yet—': 3741, 'queen': 3742, 'sardonic': 3743, '515': 3744, 'chagrin': 3745, 'hoarsely': 3746, 'dismantled': 3747, 'drawers': 3748, 'ransacked': 3749, 'plunging': 3750, 'superscribed': 3751, 'preceding': 3752, 'holmes—you': 3753, 'warned': 3754, 'reveal': 3755, 'freedom': 3756, 'celebrated': 3757, 'imprudently': 3758, 'antagonist': 3759, 'hindrance': 3760, 'safeguard': 3761, 'née': 3762, 'woman—oh': 3763, 'inviolate': 3764, 'ring—': 3765, 'emerald': 3766, 'irene’s': 3767, 'refers': 3768, 'ii': 3769, 'autumn': 3770, 'floridfaced': 3771, 'fiery': 3772, 'fatencircled': 3773, 'settee': 3774, 'relapsing': 3775, 'conventions': 3776, 'humdrum': 3777, 'everyday': 3778, 'relish': 3779, 'enthusiasm': 3780, 'combinations': 3781, 'proposition': 3782, 'piling': 3783, 'breaks': 3784, 'acknowledges': 3785, 'strangest': 3786, 'portly': 3787, 'greatcoat': 3788, 'pompous': 3789, 'overclean': 3790, 'unbuttoned': 3791, 'brassy': 3792, 'ornament': 3793, 'frayed': 3794, 'blazing': 3795, 'discontent': 3796, 'freemason': 3797, 'goodfortune': 3798, 'gospel': 3799, 'intelligence': 3800, 'rules': 3801, 'arcandcompass': 3802, 'inches': 3803, 'smooth': 3804, 'fish': 3805, 'tattooed': 3806, 'contributed': 3807, 'staining': 3808, 'fishes’': 3809, 'scales': 3810, 'watchchain': 3811, 'explaining': 3812, '‘omne': 3813, 'ignotum': 3814, 'pro': 3815, 'magnifico’': 3816, 'reputation': 3817, 'candid': 3818, 'lebanon': 3819, 'pennsylvania': 3820, 'usa': 3821, 'entitles': 3822, 'nominal': 3823, 'fleet': 3824, 'ejaculated': 3825, 'wriggled': 3826, 'mopping': 3827, 'assistants': 3828, 'obliging': 3829, 'photography': 3830, 'snapping': 3831, 'camera': 3832, 'improving': 3833, 'diving': 3834, 'develop': 3835, 'worker': 3836, 'clean—that’s': 3837, 'widower': 3838, '‘why’': 3839, '‘here’s': 3840, 'trustees': 3841, 'wits’': 3842, 'stayathome': 3843, 'doormat': 3844, 'worth’': 3845, 'interfere': 3846, 'providing': 3847, '‘but’': 3848, 'millions': 3849, 'londoners': 3850, 'competition': 3851, 'tramped': 3852, 'coster’s': 3853, 'barrow': 3854, 'were—straw': 3855, 'lemon': 3856, 'irishsetter': 3857, 'liver': 3858, 'vivid': 3859, 'butted': 3860, 'wedged': 3861, 'entertaining': 3862, 'refreshed': 3863, 'redder': 3864, 'disqualify': 3865, 'favourable': 3866, 'suited': 3867, 'requirement': 3868, 'bashful': 3869, 'congratulated': 3870, 'injustice': 3871, 'hesitate’': 3872, 'precaution’': 3873, 'eyes’': 3874, 'deceived': 3875, 'wigs': 3876, 'cobbler’s': 3877, 'wax': 3878, 'groan': 3879, 'trooped': 3880, 'redhead': 3881, 'name’': 3882, 'pensioners': 3883, 'redheads': 3884, 'another’': 3885, 'stretch': 3886, 'hours’': 3887, '‘ten': 3888, 'forfeit': 3889, 'budge': 3890, 'avail’': 3891, 'blottingpaper': 3892, 'provide': 3893, '‘certainly’': 3894, 'gain’': 3895, 'hoax': 3896, 'fraud': 3897, 'copying': 3898, 'cheer': 3899, 'quillpen': 3900, 'planked': 3901, 'sovereigns': 3902, 'billet': 3903, 'archery': 3904, 'armour': 3905, 'architecture': 3906, 'attica': 3907, 'diligence': 3908, 'foolscap': 3909, 'writings': 3910, 'hammered': 3911, 'dissolved': 3912, 'october': 3913, 'surveyed': 3914, 'curt': 3915, 'overtopped': 3916, 'flushing': 3917, 'flaming': 3918, 'shoving': 3919, 'refreshingly': 3920, '‘his': 3921, 'temporary': 3922, 'manufactory': 3923, 'artificial': 3924, 'kneecaps': 3925, 'grievance': 3926, 'prank—if': 3927, 'endeavour': 3928, 'advertisement—how': 3929, 'handy': 3930, 'stoutbuilt': 3931, 'gipsy': 3932, 'attended': 3933, 'puzzling': 3934, 'identify': 3935, 'sarasate': 3936, 'plays': 3937, 'patients': 3938, 'programme': 3939, 'italian': 3940, 'underground': 3941, 'dingy': 3942, 'railedin': 3943, 'clumps': 3944, 'faded': 3945, 'uncongenial': 3946, 'atmosphere': 3947, 'gilt': 3948, 'balls': 3949, 'thumped': 3950, 'brightlooking': 3951, 'promptly': 3952, 'smartest': 3953, 'counts': 3954, 'spies': 3955, 'explore': 3956, 'parts': 3957, 'arteries': 3958, 'roadway': 3959, 'blocked': 3960, 'inward': 3961, 'outward': 3962, 'swarm': 3963, 'pedestrians': 3964, 'shops': 3965, 'abutted': 3966, 'hobby': 3967, 'mortimer’s': 3968, 'tobacconist': 3969, 'mcfarlane’s': 3970, 'carriagebuilding': 3971, 'depot': 3972, 'we’ve': 3973, 'sandwich': 3974, 'sweetness': 3975, 'harmony': 3976, 'vex': 3977, 'musician': 3978, 'performer': 3979, 'composer': 3980, 'languid': 3981, 'dreamy': 3982, 'sleuthhound': 3983, 'relentless': 3984, 'readyhanded': 3985, 'dual': 3986, 'asserted': 3987, 'exactness': 3988, 'astuteness': 3989, 'represented': 3990, 'poetic': 3991, 'contemplative': 3992, 'predominated': 3993, 'languor': 3994, 'devouring': 3995, 'improvisations': 3996, 'blackletter': 3997, 'unacquainted': 3998, 'askance': 3999, 'mortals': 4000, 'hunt': 4001, 'contemplation': 4002, 'complicates': 4003, 'army': 4004, 'heel': 4005, 'oppressed': 4006, 'stupidity': 4007, 'confused': 4008, 'grotesque': 4009, 'kensington': 4010, 'copier': 4011, 'smoothfaced': 4012, 'hansoms': 4013, 'voices': 4014, 'we’re': 4015, 'couples': 4016, 'consequential': 4017, 'loftily': 4018, 'makings': 4019, 'agra': 4020, 'sevenandtwenty': 4021, 'stake': 4022, 'exciting': 4023, 'smasher': 4024, 'forger': 4025, 'bracelets': 4026, 'eton': 4027, 'he’ll': 4028, 'build': 4029, 'communicative': 4030, 'humming': 4031, 'tunes': 4032, 'rattled': 4033, 'farrington': 4034, 'bulldog': 4035, 'dismissed': 4036, 'guidance': 4037, 'conducted': 4038, 'piled': 4039, 'crates': 4040, 'vulnerable': 4041, 'below': 4042, 'flags': 4043, 'severely': 4044, 'imperilled': 4045, 'boxes': 4046, 'cracks': 4047, 'satisfy': 4048, 'pawnbroker': 4049, 'divined—in': 4050, 'banks': 4051, '2000': 4052, 'layers': 4053, 'bullion': 4054, 'justified': 4055, 'meantime': 4056, 'screen': 4057, 'partie': 4058, 'carrée': 4059, 'positions': 4060, 'disadvantage': 4061, 'crate': 4062, 'shooting': 4063, 'crouched': 4064, 'slide': 4065, 'darkness—such': 4066, 'experienced': 4067, 'depressing': 4068, 'subduing': 4069, 'dank': 4070, 'retreat': 4071, 'officers': 4072, 'comparing': 4073, 'dawn': 4074, 'stiff': 4075, 'heavier': 4076, 'inbreath': 4077, 'sighing': 4078, 'glint': 4079, 'lurid': 4080, 'gash': 4081, 'gaping': 4082, 'cleancut': 4083, 'shoulderhigh': 4084, 'waisthigh': 4085, 'hauling': 4086, 'scott': 4087, 'archie': 4088, 'sprung': 4089, 'dived': 4090, 'skirts': 4091, 'clinked': 4092, 'climbing': 4093, 'handcuffs': 4094, '‘sir’': 4095, 'stare': 4096, 'highness': 4097, 'serenely': 4098, 'detected': 4099, 'scores': 4100, 'amply': 4101, 'repaid': 4102, 'managing': 4103, 'clay’s': 4104, 'accomplice’s': 4105, 'incites': 4106, 'securing': 4107, 'intrigue': 4108, 'elaborate': 4109, 'preparations': 4110, 'assistant’s': 4111, 'cellar—something': 4112, 'skirmishes': 4113, 'burrowing': 4114, 'concert': 4115, 'presence—in': 4116, 'ennui': 4117, 'yawning': 4118, 'race': 4119, '‘l’homme': 4120, 'rien—l’œuvre': 4121, 'gustave': 4122, 'flaubert': 4123, 'iii': 4124, 'conceive': 4125, 'peep': 4126, 'coincidences': 4127, 'plannings': 4128, 'crosspurposes': 4129, 'chains': 4130, 'generations': 4131, 'fiction': 4132, 'conventionalities': 4133, 'reports': 4134, 'realism': 4135, 'selection': 4136, 'realistic': 4137, 'wanting': 4138, 'report': 4139, 'stress': 4140, 'vital': 4141, 'essence': 4142, 'everybody': 4143, 'throughout': 4144, 'here—i': 4145, 'heading': 4146, 'wife’': 4147, 'bruise': 4148, 'sympathetic': 4149, 'crudest': 4150, 'dundas': 4151, 'separation': 4152, 'teetotaler': 4153, 'drifted': 4154, 'hurling': 4155, 'storyteller': 4156, 'pinch': 4157, 'snuffbox': 4158, 'splendour': 4159, 'souvenir': 4160, 'apt': 4161, 'bigger': 4162, 'neutraltinted': 4163, 'boa': 4164, 'tilted': 4165, 'devonshire': 4166, 'hesitating': 4167, 'oscillated': 4168, 'plunge': 4169, 'oscillation': 4170, 'affaire': 4171, 'cœur': 4172, 'discriminate': 4173, 'oscillates': 4174, 'symptom': 4175, 'perplexed': 4176, 'grieved': 4177, 'resolve': 4178, 'fullsailed': 4179, 'merchantman': 4180, 'pilot': 4181, 'boat': 4182, 'welcomed': 4183, 'goodhumoured': 4184, 'father—took': 4185, 'tidy': 4186, 'wines': 4187, '4700': 4188, 'wasn’t': 4189, 'inconsequential': 4190, 'concentration': 4191, 'auckland': 4192, 'zealand': 4193, 'pays': 4194, 'sutherland’s': 4195, 'tickets': 4196, 'purple': 4197, 'plush': 4198, 'gasfitters’': 4199, 'hosmer—mr': 4200, 'angel—was': 4201, 'worst': 4202, 'no—except': 4203, 'clerks': 4204, 'typewrite': 4205, 'infinitely': 4206, 'shy': 4207, 'daylight': 4208, 'conspicuous': 4209, 'retiring': 4210, 'gentlemanly': 4211, 'he’d': 4212, 'quinsy': 4213, 'swollen': 4214, 'glands': 4215, 'whispering': 4216, 'fonder': 4217, 'marrying': 4218, 'sly': 4219, 'pledged': 4220, 'weddingmorning': 4221, 'catastrophe': 4222, 'foresaw': 4223, 'notion': 4224, 'drives': 4225, 'halfmad': 4226, 'saturday’s': 4227, '31': 4228, 'lyon': 4229, 'angel’s': 4230, 'travels': 4231, 'claret': 4232, 'vacuous': 4233, 'whenever': 4234, 'oily': 4235, 'spinning': 4236, 'trite': 4237, 'andover': 4238, '’77': 4239, 'invisible': 4240, 'unnoticed': 4241, 'suggestiveness': 4242, 'issues': 4243, 'hang': 4244, 'slatecoloured': 4245, 'straw': 4246, 'brickish': 4247, 'earrings': 4248, 'easygoing': 4249, 'concentrate': 4250, 'trouser': 4251, 'useful': 4252, 'defined': 4253, 'sewingmachine': 4254, 'type': 4255, 'farthest': 4256, 'broadest': 4257, 'dint': 4258, 'pincenez': 4259, 'unlike': 4260, 'slightly': 4261, 'decorated': 4262, 'toecap': 4263, 'fifth': 4264, 'dipped': 4265, 'elementary': 4266, 'fourteenth': 4267, 'ft': 4268, 'bald': 4269, 'bushy': 4270, 'infirmity': 4271, 'harris': 4272, 'tweed': 4273, 'anybody': 4274, 'quotes': 4275, '‘hosmer': 4276, 'angel’': 4277, 'superscription': 4278, 'suggestive—in': 4279, 'deny': 4280, 'breach': 4281, 'fathom': 4282, 'weird': 4283, 'tangle': 4284, 'disappearing': 4285, 'gravity': 4286, 'engaging': 4287, 'array': 4288, 'testtubes': 4289, 'pungent': 4290, 'cleanly': 4291, 'hydrochloric': 4292, 'acid': 4293, 'bisulphate': 4294, 'salt': 4295, 'sturdy': 4296, 'sallowskinned': 4297, 'wonderfully': 4298, 'tophat': 4299, 'nearest': 4300, 'excitable': 4301, 'impulsive': 4302, 'noised': 4303, 'slurring': 4304, '‘e’': 4305, '‘r’': 4306, '‘r’s’': 4307, 'tailless': 4308, 'alluded': 4309, 'waste': 4310, 'do—really': 4311, 'it—it’s': 4312, 'actionable': 4313, 'selfish': 4314, 'contradict': 4315, 'enjoyed': 4316, 'warmhearted': 4317, 'restive': 4318, 'rights': 4319, 'conceives': 4320, 'connivance': 4321, 'disguised': 4322, 'whisper': 4323, 'doubly': 4324, 'lovers': 4325, 'treachery': 4326, 'admiration': 4327, 'affections': 4328, 'deception': 4329, 'pretended': 4330, 'journeys': 4331, 'permanent': 4332, 'allusions': 4333, 'happening': 4334, 'conveniently': 4335, 'assurance': 4336, 'assault': 4337, 'illegal': 4338, 'to—': 4339, 'banged': 4340, 'coldblooded': 4341, 'hinted': 4342, 'suspicions': 4343, 'confirmed': 4344, 'inferred': 4345, 'isolated': 4346, 'verify': 4347, 'spotted': 4348, 'eliminated': 4349, 'disguise—the': 4350, 'travellers': 4351, 'peculiarities': 4352, 'defects': 4353, 'tallied': 4354, 'respect': 4355, 'voilà': 4356, 'persian': 4357, 'whoso': 4358, 'snatches': 4359, 'delusion': 4360, 'hafiz': 4361, 'horace': 4362, 'iv': 4363, 'anstruther': 4364, 'afghanistan': 4365, 'valise': 4366, 'taller': 4367, 'travellingcloak': 4368, 'closefitting': 4369, 'worthless': 4370, 'seats': 4371, 'notetaking': 4372, 'meditation': 4373, 'profoundly': 4374, 'singularity': 4375, 'featureless': 4376, 'herefordshire': 4377, 'landed': 4378, 'australia': 4379, 'farms': 4380, 'charles': 4381, 'tenant': 4382, 'wives': 4383, 'avoided': 4384, 'sport': 4385, 'racemeetings': 4386, 'servants—a': 4387, 'servingman': 4388, 'farmhouse': 4389, 'employ': 4390, 'language': 4391, 'inflicted': 4392, 'buttend': 4393, '‘wilful': 4394, 'murder’': 4395, 'magistrates': 4396, 'tricky': 4397, 'thoughtfully': 4398, 'shift': 4399, 'uncompromising': 4400, 'recollect': 4401, 'westward': 4402, 'breakfasts': 4403, 'deceptive': 4404, 'boasting': 4405, 'destroy': 4406, 'employing': 4407, 'understanding': 4408, 'selfevident': 4409, 'characterises': 4410, 'sunlight': 4411, 'shaving': 4412, 'slovenly': 4413, 'illuminated': 4414, 'quote': 4415, 'inference': 4416, 'therein': 4417, 'métier': 4418, 'removing': 4419, 'minds': 4420, 'coroner’s': 4421, 'protestation': 4422, 'feigned': 4423, 'scheming': 4424, 'acceptance': 4425, 'firmness': 4426, 'filial': 4427, 'bandy': 4428, 'encouraging': 4429, 'follows': 4430, 'absent': 4431, 'cobb': 4432, 'visiting': 4433, 'cooee': 4434, 'ensued': 4435, 'becoming': 4436, 'ungovernable': 4437, 'outcry': 4438, 'expiring': 4439, 'expired': 4440, 'knelt': 4441, 'mumbled': 4442, 'refusal': 4443, 'prejudice': 4444, '(with': 4445, 'confusion)': 4446, 'juryman': 4447, 'plaid': 4448, '‘about': 4449, 'concluding': 4450, 'discrepancy': 4451, 'signalled': 4452, 'cushioned': 4453, 'imagination': 4454, 'evolved': 4455, 'swindon': 4456, 'stroud': 4457, 'gleaming': 4458, 'countrytown': 4459, 'ferretlike': 4460, 'furtive': 4461, 'slylooking': 4462, 'dustcoat': 4463, 'rustic': 4464, 'recognising': 4465, 'complimentary': 4466, 'barometric': 4467, 'twentynine': 4468, 'caseful': 4469, 'cigarettes': 4470, 'superior': 4471, 'indulgently': 4472, 'pikestaff': 4473, 'loophole': 4474, 'hide': 4475, 'disagreements': 4476, 'and—and—well': 4477, 'blush': 4478, 'glances': 4479, 'willows': 4480, 'goldmines': 4481, 'impulsively': 4482, 'disappoint': 4483, 'overtender': 4484, 'reconsider': 4485, 'puny': 4486, 'supposing': 4487, 'calamity': 4488, 'screams': 4489, 'glade': 4490, 'instincts': 4491, 'weekly': 4492, 'contained': 4493, 'verbatim': 4494, 'surgeon’s': 4495, 'deposition': 4496, 'parietal': 4497, 'delirium': 4498, 'commonly': 4499, 'delirious': 4500, 'cudgelled': 4501, 'improbabilities': 4502, 'comely': 4503, 'thereby': 4504, 'insanely': 4505, 'boardingschool': 4506, 'idiot': 4507, 'upbraided': 4508, 'goading': 4509, 'bermuda': 4510, 'dockyard': 4511, 'crucial': 4512, 'meredith': 4513, 'foretold': 4514, 'sixty': 4515, 'constitution': 4516, 'speaks': 4517, 'obligations': 4518, 'proposal': 4519, 'winking': 4520, 'demurely': 4521, 'tackle': 4522, 'senior': 4523, 'brighter': 4524, 'slateroofed': 4525, 'lichen': 4526, 'transformed': 4527, 'darkened': 4528, 'sinewy': 4529, 'dilate': 4530, 'concentrated': 4531, 'unheeded': 4532, 'meadows': 4533, 'bounded': 4534, 'detour': 4535, 'meadow': 4536, 'indifferent': 4537, 'contemptuous': 4538, 'reedgirt': 4539, 'boundary': 4540, 'pinnacles': 4541, 'site': 4542, 'sodden': 4543, 'fished': 4544, 'rake': 4545, 'mole': 4546, 'vanishes': 4547, 'herd': 4548, 'listening': 4549, 'again—of': 4550, 'beech': 4551, 'sticks': 4552, 'jagged': 4553, 'luncheon': 4554, 'limps': 4555, 'thicksoled': 4556, 'shootingboots': 4557, 'cigarholder': 4558, 'penknife': 4559, 'nous': 4560, 'verrons': 4561, 'populous': 4562, 'undertake': 4563, 'laughingstock': 4564, 'pained': 4565, 'perplexing': 4566, 'preach': 4567, 'research': 4568, 'presuming': 4569, 'earshot': 4570, 'attract': 4571, 'arat': 4572, 'syllables': 4573, 'garment': 4574, 'granting': 4575, 'vagueness': 4576, 'personality': 4577, 'roughly': 4578, 'stride': 4579, 'varieties': 4580, 'tip': 4581, 'clean': 4582, 'net': 4583, 'waiter': 4584, 'ushering': 4585, 'limping': 4586, 'deeplined': 4587, 'craggy': 4588, 'combined': 4589, 'ashen': 4590, 'nostrils': 4591, 'tinged': 4592, 'heart—it': 4593, 'required': 4594, 'jot': 4595, '’60’s': 4596, 'hotblooded': 4597, 'bush': 4598, 'robber': 4599, 'diggings': 4600, 'jack': 4601, 'convoy': 4602, 'volley': 4603, 'boys': 4604, 'swag': 4605, 'spared': 4606, 'wicked': 4607, 'pals': 4608, 'wee': 4609, '‘here': 4610, 'jack’': 4611, 'touching': 4612, 'don’t—it’s': 4613, 'grinning': 4614, 'cursed': 4615, 'midway': 4616, 'uppermost': 4617, 'urging': 4618, 'regard': 4619, 'bond': 4620, 'limb': 4621, 'sinned': 4622, 'venomous': 4623, 'beast': 4624, 'fetch': 4625, 'farewell': 4626, 'tottering': 4627, 'stumbled': 4628, 'tricks': 4629, 'worms': 4630, 'baxter’s': 4631, 'acquitted': 4632, 'defending': 4633, 'counsel': 4634, 'cloud': 4635, 'rests': 4636, '’82': 4637, '’90': 4638, 'qualities': 4639, 'beginnings': 4640, 'startling': 4641, '’87': 4642, 'paradol': 4643, 'amateur': 4644, 'mendicant': 4645, 'vault': 4646, 'grice': 4647, 'patersons': 4648, 'camberwell': 4649, 'poisoning': 4650, 'september': 4651, 'handmade': 4652, 'elemental': 4653, 'forces': 4654, 'mankind': 4655, 'civilisation': 4656, 'untamed': 4657, 'beasts': 4658, 'cage': 4659, 'moodily': 4660, 'crossindexing': 4661, 'clark': 4662, 'russell’s': 4663, 'seastories': 4664, 'blend': 4665, 'lengthen': 4666, 'swash': 4667, 'crony': 4668, 'twoandtwenty': 4669, 'wellgroomed': 4670, 'trimly': 4671, 'refinement': 4672, 'streaming': 4673, 'anxiously': 4674, 'intruding': 4675, 'hook': 4676, 'dry': 4677, 'southwest': 4678, 'chalk': 4679, 'mixture': 4680, 'tankerville': 4681, 'wrongfully': 4682, 'times—three': 4683, 'compared': 4684, 'joseph': 4685, 'factory': 4686, 'enlarged': 4687, 'invention': 4688, 'unbreakable': 4689, 'tire': 4690, 'emigrated': 4691, 'planter': 4692, 'fought': 4693, 'hood': 4694, '1870': 4695, 'sussex': 4696, 'negroes': 4697, 'dislike': 4698, 'policy': 4699, 'franchise': 4700, 'foulmouthed': 4701, '1878': 4702, 'sober': 4703, 'draughts': 4704, 'tradespeople': 4705, 'sixteen': 4706, 'liked': 4707, 'privacy': 4708, 'exception': 4709, 'attics': 4710, 'permit': 4711, 'boy’s': 4712, 'bundles': 4713, 'day—it': 4714, '1883—a': 4715, 'colonel’s': 4716, 'bills': 4717, '‘pondicherry': 4718, 'be’': 4719, 'skin': 4720, 'putty': 4721, 'uncle’': 4722, '‘death’': 4723, 'breakfasttable': 4724, 'rusty': 4725, 'cashbox': 4726, 'oath': 4727, 'fordham': 4728, 'mass': 4729, 'enjoy': 4730, 'twoedged': 4731, 'pondered': 4732, 'drank': 4733, 'drunken': 4734, 'frenzy': 4735, 'tumultuously': 4736, 'brazen': 4737, 'glisten': 4738, 'sallies': 4739, 'verdict': 4740, '‘suicide’': 4741, 'winced': 4742, '14000': 4743, 'interposed': 4744, 'reception': 4745, 'supposed': 4746, '10': 4747, '1883': 4748, '‘letters': 4749, 'memoranda': 4750, 'receipts': 4751, 'notebooks': 4752, 'soldier': 4753, 'reconstruction': 4754, 'carpetbag': 4755, 'politicians': 4756, 'cockandbull': 4757, 'scared': 4758, '‘so': 4759, 'is’': 4760, '‘pooh’': 4761, 'gripping': 4762, 'courage': 4763, 'tomfoolery': 4764, '‘from': 4765, 'dundee’': 4766, 'joke’': 4767, 'sundials': 4768, 'police’': 4769, 'pains': 4770, 'forbid': 4771, 'argue': 4772, 'forts': 4773, 'portsdown': 4774, 'hill': 4775, 'major': 4776, 'twilight': 4777, 'unfenced': 4778, 'accidental': 4779, 'causes’': 4780, 'strangers': 4781, 'wellnigh': 4782, 'dispose': 4783, 'dependent': 4784, 'comfort': 4785, '‘k': 4786, 'k’': 4787, 'truth—he': 4788, 'resistless': 4789, 'inexorable': 4790, 'jokes': 4791, 'clenched': 4792, 'raved': 4793, 'advised': 4794, 'us—no': 4795, 'unburned': 4796, 'margins': 4797, 'fluttered': 4798, 'destruction': 4799, 'ragged': 4800, 'headed': 4801, '7th': 4802, '10th': 4803, 'swain': 4804, '12th': 4805, 'folding': 4806, 'assert': 4807, 'revenge': 4808, 'weave': 4809, 'theirs': 4810, 'punish': 4811, 'meanwhile': 4812, 'imminent': 4813, 'splashed': 4814, 'pattered': 4815, 'elements—blown': 4816, 'reabsorbed': 4817, 'chased': 4818, 'ideal': 4819, 'bearings': 4820, 'correctly': 4821, 'sought': 4822, 'education': 4823, 'encyclopædias': 4824, 'accomplishment': 4825, 'limits': 4826, 'astronomy': 4827, 'zero': 4828, 'variable': 4829, 'geology': 4830, 'mudstains': 4831, 'chemistry': 4832, 'anatomy': 4833, 'sensational': 4834, 'violinplayer': 4835, 'swordsman': 4836, 'selfpoisoner': 4837, 'grinned': 4838, 'library': 4839, 'muster': 4840, 'willingly': 4841, 'climate': 4842, 'provincial': 4843, 'suggests': 4844, 'successors': 4845, 'postmarks': 4846, 'seaports': 4847, 'probability—the': 4848, 'probability—is': 4849, 'threat': 4850, 'token': 4851, 'mailboat': 4852, 'sailing': 4853, 'vessel': 4854, 'persons': 4855, 'determination': 4856, 'never—': 4857, 'voice—have': 4858, 'ku': 4859, '‘ku': 4860, 'klan': 4861, 'cocking': 4862, 'rifle': 4863, 'exconfederate': 4864, 'soldiers': 4865, 'branches': 4866, 'notably': 4867, 'tennessee': 4868, 'louisiana': 4869, 'carolinas': 4870, 'terrorising': 4871, 'negro': 4872, 'voters': 4873, 'opposed': 4874, 'preceded': 4875, 'recognised': 4876, 'shape—a': 4877, 'sprig': 4878, 'oakleaves': 4879, 'melon': 4880, 'seeds': 4881, 'abjure': 4882, 'systematic': 4883, 'impunity': 4884, 'perpetrators': 4885, 'flourished': 4886, 'united': 4887, 'classes': 4888, 'community': 4889, 'sporadic': 4890, 'outbreaks': 4891, 'coincident': 4892, 'implacable': 4893, 'register': 4894, 'diary': 4895, 'c’—that': 4896, 'successive': 4897, 'brightness': 4898, 'foresee': 4899, 'unopened': 4900, 'bridge’': 4901, '‘between': 4902, 'policeconstable': 4903, 'cook': 4904, 'splash': 4905, 'rescue': 4906, 'waterpolice': 4907, 'exhibited': 4908, 'condition': 4909, 'sends': 4910, 'death—': 4911, 'clasping': 4912, 'unclasping': 4913, 'devils': 4914, 'embankment': 4915, 'flies': 4916, 'devoured': 4917, 'voraciously': 4918, 'washing': 4919, 'starving': 4920, 'unavenged': 4921, 'squeezed': 4922, 'await': 4923, 'enters': 4924, 'port': 4925, 'sleepless': 4926, 'captain': 4927, 'leader': 4928, 'files': 4929, 'ships': 4930, 'tonnage': 4931, 'texas': 4932, 'inquired': 4933, 'vessels': 4934, 'isle': 4935, 'nativeborn': 4936, 'americans': 4937, 'germans': 4938, 'stevedore': 4939, 'reaches': 4940, 'cable': 4941, 'murderers': 4942, 'gales': 4943, 'atlantic': 4944, 'sternpost': 4945, 'trough': 4946, 'vi': 4947, 'theological': 4948, 'addicted': 4949, 'quincey’s': 4950, 'sensations': 4951, 'slave': 4952, 'pasty': 4953, 'pinpoint': 4954, 'pupils': 4955, 'wreck': 4956, '’89—there': 4957, 'yawn': 4958, 'linoleum': 4959, 'darkcoloured': 4960, 'stuff': 4961, 'sobbed': 4962, 'comfortably': 4963, 'doctor’s': 4964, 'soothed': 4965, 'comforted': 4966, 'hitherto': 4967, 'orgies': 4968, 'twitching': 4969, 'spell': 4970, 'eightandforty': 4971, 'dregs': 4972, 'docks': 4973, 'timid': 4974, 'speeding': 4975, 'eastward': 4976, 'alley': 4977, 'lurking': 4978, 'slopshop': 4979, 'ginshop': 4980, 'gap': 4981, 'ordering': 4982, 'flickering': 4983, 'latch': 4984, 'terraced': 4985, 'forecastle': 4986, 'emigrant': 4987, 'poses': 4988, 'chins': 4989, 'lacklustre': 4990, 'circles': 4991, 'waxed': 4992, 'waned': 4993, 'gushes': 4994, 'tailing': 4995, 'heed': 4996, 'neighbour': 4997, 'threelegged': 4998, 'stool': 4999, 'jaw': 5000, 'resting': 5001, 'malay': 5002, 'beckoning': 5003, 'twitter': 5004, 'chap': 5005, 'treble': 5006, 'pipes': 5007, 'pipes—i': 5008, 'kate—poor': 5009, 'brazier': 5010, 'wrinkles': 5011, 'subsided': 5012, 'rid': 5013, 'mastery': 5014, 'decrepit': 5015, 'shuffled': 5016, 'straightened': 5017, 'opiumsmoking': 5018, 'injections': 5019, 'weaknesses': 5020, 'purchase': 5021, 'rascally': 5022, 'vengeance': 5023, 'trapdoor': 5024, 'paul’s': 5025, 'tales': 5026, 'bodies': 5027, 'murdertrap': 5028, 'forefingers': 5029, 'tunnels': 5030, 'lanterns': 5031, 'comrade': 5032, 'kent': 5033, 'sevenmile': 5034, 'flicked': 5035, 'murky': 5036, 'flowing': 5037, 'sluggishly': 5038, 'wilderness': 5039, 'mortar': 5040, 'footfall': 5041, 'songs': 5042, 'belated': 5043, 'revellers': 5044, 'wrack': 5045, 'sorely': 5046, 'villas': 5047, 'gift': 5048, 'overpleasant': 5049, 'meets': 5050, 'absurdly': 5051, 'thread': 5052, 'ago—to': 5053, '1884—there': 5054, 'degrees': 5055, '1887': 5056, 'companies': 5057, '514': 5058, 'cannon': 5059, 'thirtyseven': 5060, '220': 5061, 'weighing': 5062, 'commissions': 5063, 'parcel': 5064, 'shopping': 5065, 'describes': 5066, 'plucked': 5067, 'amiss': 5068, 'steps—for': 5069, 'tonight—and': 5070, 'ascend': 5071, 'aided': 5072, 'resistance': 5073, 'crippled': 5074, 'wretch': 5075, 'denial': 5076, 'deluded': 5077, 'cascade': 5078, 'confusion': 5079, 'curtain': 5080, 'socks': 5081, 'watch—all': 5082, 'exit': 5083, 'bloodstains': 5084, 'swimming': 5085, 'villains': 5086, 'defence': 5087, 'ignorance': 5088, 'doings': 5089, 'regulations': 5090, 'pretends': 5091, 'vestas': 5092, 'tiny': 5093, 'charity': 5094, 'descends': 5095, 'reaped': 5096, 'disfigured': 5097, 'outer': 5098, 'mendicants': 5099, 'chaff': 5100, 'prime': 5101, 'weakness': 5102, 'compensated': 5103, 'mistake': 5104, 'incriminate': 5105, 'shirtsleeve': 5106, 'ringfinger': 5107, 'nail': 5108, 'adding': 5109, 'source': 5110, 'denied': 5111, 'strenuously': 5112, 'swore': 5113, 'dreaming': 5114, 'protesting': 5115, 'policestation': 5116, 'ebbing': 5117, 'uncovered': 5118, 'receded': 5119, 'halfpennies—421': 5120, 'pennies': 5121, '270': 5122, 'halfpennies': 5123, 'eddy': 5124, 'weighted': 5125, 'stripped': 5126, 'sucked': 5127, 'telltale': 5128, 'seize': 5129, 'confederate': 5130, 'accumulated': 5131, 'fruits': 5132, 'coins': 5133, 'coat’s': 5134, 'hugh': 5135, 'disappearance—are': 5136, 'detailing': 5137, 'whirling': 5138, 'straggling': 5139, 'counties': 5140, 'conducting': 5141, 'hate': 5142, 'whoa': 5143, 'soie': 5144, 'chiffon': 5145, 'outlined': 5146, 'flood': 5147, 'halfraised': 5148, 'arrangements': 5149, 'feelings': 5150, 'hearts': 5151, 'embarrassed': 5152, 'stamped': 5153, 'whoever': 5154, 'pause': 5155, 'trifles': 5156, '‘dearest': 5157, 'patience—neville’': 5158, 'flyleaf': 5159, 'octavo': 5160, 'watermark': 5161, 'lighten': 5162, 'venture': 5163, 'forgery': 5164, 'discourage': 5165, 'respond': 5166, 'trifle': 5167, 'arguments': 5168, 'wasted': 5169, 'horribly': 5170, 'muzzle': 5171, 'worrying': 5172, 'doorstep': 5173, 'cruelty’s': 5174, 'winecellar': 5175, 'mastiff’': 5176, 'known—’': 5177, 'know’': 5178, 'door’': 5179, 'lady’': 5180, 'panted': 5181, 'open’': 5182, 'uncarpeted': 5183, 'jest': 5184, 'up’': 5185, 'shuttered': 5186, 'puzzle': 5187, 'obtruded': 5188, 'pack': 5189, 'calf': 5190, 'beauty’': 5191, 'notice’': 5192, 'away’': 5193, 'parts’': 5194, 'southampton': 5195, 'inimitably': 5196, 'dashing': 5197, 'nursery': 5198, 'funniest': 5199, 'obliged’': 5200, 'mice': 5201, 'savage': 5202, 'bluff': 5203, 'philadelphia': 5204, 'countryside': 5205, 'projecting': 5206, 'homesteads': 5207, 'foliage': 5208, 'aldershot': 5209, '1130': 5210, 'studies': 5211, 'grateful': 5212, 'grating': 5213, 'danger—': 5214, 'outbreak': 5215, 'rucastle’': 5216, 'amusing': 5217, 'wash': 5218, 'stoper’': 5219, 'cells': 5220, 'annoyance': 5221, 'hair’': 5222, 'ladies’': 5223, 'us’': 5224, 'no’': 5225, 'useful’': 5226, 'heh’': 5227, 'child’': 5228, 'countryhouse’': 5229, 'wardrobe’': 5230, 'year’': 5231, 'drawing—’': 5232, 'accomplishments’': 5233, 'munro’': 5234, 'ask’': 5235, 'governess’': 5236, 'sir’': 5237, 'comfortablelooking': 5238, 'whim': 5239, 'unobservant': 5240, 'shortcomings': 5241, 'continuously': 5242, 'wont': 5243, 'prominence': 5244, 'smudge': 5245, 'random': 5246, 'chivalrous': 5247, 'thrilling': 5248, 'england—a': 5249, '4000': 5250, '‘mary’': 5251, 'fruitless': 5252, 'lethargy': 5253, 'self': 5254, 'class': 5255, 'altered': 5256, 'luck': 5257, 'prosper': 5258, 'sweetheart': 5259, 'cousin': 5260, 'suspect': 5261, 'harshly': 5262, 'caress': 5263, 'evenings': 5264, 'crying': 5265, 'financier': 5266, 'tenable': 5267, 'straighten': 5268, 'fourandtwenty': 5269, 'knitted': 5270, 'fro': 5271, 'forgotten’': 5272, 'can’': 5273, 'takings': 5274, 'bottom’': 5275, 'world’': 5276, 'piece’': 5277, 'stolen’': 5278, 'lucid': 5279, 'fastened’': 5280, 'stopped’': 5281, 'not’': 5282, 'tonight’': 5283, '‘did': 5284, 'means’': 5285, 'again’': 5286, 'matters’': 5287, '200’': 5288, 'cupboard’': 5289, 'bureau’': 5290, 'insight': 5291, 'sums': 5292, 'sterner': 5293, 'grievous': 5294, 'reliability': 5295, 'maidservants': 5296, 'alter': 5297, 'morning’': 5298, '‘ample’': 5299, 'sufficient’': 5300, 'added': 5301, 'doubt—’': 5302, 'security’': 5303, 'coronet’': 5304, 'taken’': 5305, 'owner': 5306, 'once’': 5307, 'obligations’': 5308, 'money’': 5309, 'remunerative': 5310, 'gaslight': 5311, 'citizens': 5312, 'partner': 5313, 'contortions': 5314, 'crumbly': 5315, 'gracious': 5316, 'hotels': 5317, 'miners’': 5318, 'stripes': 5319, 'lordship': 5320, 'bee': 5321, 'lasting': 5322, 'alert': 5323, 'bitterly': 5324, 'resist': 5325, 'unprecedented': 5326, 'bakers': 5327, 'crisis': 5328, 'standpoint': 5329, 'humiliation': 5330, 'confectioner’s': 5331, 'outdoor': 5332, 'rival': 5333, '2s': 5334, '‘oct': 5335, 'arrive': 5336, 'snarled': 5337, 'canvas': 5338, 'stately': 5339, 'wiser': 5340, 'retrogression': 5341, 'deranged': 5342, 'selfrespect': 5343, 'supposition': 5344, 'training': 5345, 'push': 5346, 'breakfastroom': 5347, 'reentering': 5348, 'accompli': 5349, 'fait': 5350, 'dowry': 5351, 'ivory': 5352, 'mining': 5353, 'bounds': 5354, 'slope': 5355, 'amused': 5356, 'prints': 5357, 'pardon': 5358, 'descending': 5359, 'eyeglasses': 5360, 'lightcoloured': 5361, 'highnosed': 5362, 'danseuse': 5363, 'bride’': 5364, 'lancaster': 5365, 'backwater': 5366, 'wedding’': 5367, '‘singular': 5368, 'incomplete': 5369, 'bird’s': 5370, 'honeymoon': 5371, 'stain': 5372, 'peeress’': 5373, 'transition': 5374, 'california': 5375, 'prizes': 5376, 'freetrade': 5377, 'apartment': 5378, 'selections': 5379, 'van': 5380, 'simon’': 5381, 'faithfully': 5382, 'paramount': 5383, 'tidewaiter': 5384, 'episode': 5385, 'morcar’s': 5386, 'bold': 5387, 'tin': 5388, 'sunset': 5389, 'severed': 5390, 'whereabouts': 5391, 'betterlined': 5392, 'abstracted': 5393, 'becher’s': 5394, 'landscape': 5395, 'ostrich': 5396, 'destined': 5397, 'entreaties': 5398, 'cuttings': 5399, 'dew': 5400, 'rosebushes': 5401, 'understood': 5402, 'say’': 5403, 'silent’': 5404, 'butcher’s': 5405, 'soprecious': 5406, 'rejected': 5407, 'out’': 5408, '‘hullo’': 5409, 'used’': 5410, 'shrunk': 5411, 'levers': 5412, 'fellowcountryman': 5413, 'house’': 5414, 'suppose’': 5415, 'close’': 5416, 'draught’': 5417, 'renew': 5418, 'engage': 5419, 'late’': 5420, 'machine’': 5421, 'utter': 5422, 'oak': 5423, 'glossy': 5424, 'jewels': 5425, 'chestnut': 5426, 'passenger': 5427, 'pit’': 5428, 'suicide': 5429, 'plain’': 5430, 'toy': 5431, 'engineers': 5432, 'jealously': 5433, 'place—within': 5434, 'england’': 5435, '‘entirely’': 5436, 'eavesdroppers’': 5437, 'accommodate': 5438, 'recompense': 5439, 'hour’': 5440, 'shakedown’': 5441, 'station’': 5442, '1115’': 5443, 'train’': 5444, 'munificent’': 5445, 'admirably’': 5446, 'eat': 5447, 'word’': 5448, 'writing’': 5449, 'promise’': 5450, 'london’': 5451, 'bore': 5452, 'orphan': 5453, 'character’': 5454, 'emaciation': 5455, 'exceeding': 5456, 'instituted': 5457, '‘colonel': 5458, 'stimulant': 5459, 'attack': 5460, 'province': 5461, 'passersby': 5462, 'twig': 5463, 'footfalls': 5464, 'doctors’': 5465, 'bled': 5466, 'palelooking': 5467, 'hysterical': 5468, 'caraffe': 5469, 'sidetable': 5470, 'notice—that': 5471, 'conscience': 5472, 'rapidity': 5473, 'guilt': 5474, 'serpent': 5475, 'squat': 5476, 'trim': 5477, 'swelled': 5478, 'lashed': 5479, 'befall': 5480, 'vice': 5481, 'unrepaired': 5482, 'cheerful': 5483, 'article': 5484, 'strikes': 5485, 'to’': 5486, 'd’you': 5487, 'gathering': 5488, 'undoing': 5489, 'fright': 5490, 'manage': 5491, 'headache': 5492, 'compliance': 5493, 'reverie': 5494, 'character—dummy': 5495, 'tug': 5496, 'unapproachable': 5497, 'erected': 5498, 'splendidly': 5499, 'mansion': 5500, 'argument': 5501, 'draught': 5502, 'decided': 5503, 'jackinoffice': 5504, 'daresay': 5505, 'broadened': 5506, 'busybody': 5507, 'framed': 5508, 'meddler': 5509, 'imperturbably': 5510, 'furiously': 5511, 'apparition': 5512, 'glided': 5513, 'matchbox': 5514, 'dreadfully': 5515, 'revolved': 5516, 'also’': 5517, 'plantation’': 5518, 'why’': 5519, 'sleep’': 5520, 'night’': 5521, 'neighbours': 5522, 'term': 5523, 'regency': 5524, 'consulted': 5525, 'to—none': 5526, 'patting': 5527, 'requested': 5528, 'shivering': 5529, 'chief': 5530, 'apart’': 5531, 'chose’': 5532, 'garden’': 5533, 'dealer’s’': 5534, 'flock’': 5535, 'now’': 5536, 'i’d': 5537, 'catherine': 5538, 'market’': 5539, 'fattest’': 5540, 'waitingmaid': 5541, 'temptation': 5542, 'pouring': 5543, 'bible': 5544, 'then—': 5545, 'sternly': 5546, 'accuser': 5547, 'uncertain': 5548, 'fattened': 5549, 'museum': 5550, 'dead—the': 5551, 'alias': 5552, 'assisting': 5553, 'windswept': 5554, 'flaring': 5555, 'striding': 5556, 'inquirer': 5557, 'should—': 5558, '’un’': 5559, '12s’': 5560, 'underneath': 5561, '6d’': 5562, 'jem’': 5563, 'entry': 5564, 'supplier’': 5565, 'ledger': 5566, 'obstinate': 5567, 'bred': 5568, 'akimbo': 5569, 'gasflare': 5570, 'marble': 5571, 'zigzag': 5572, 'cravats': 5573, 'pence': 5574, 'wish—': 5575, 'relief': 5576, 'cuff': 5577, 'gazette': 5578, 'concise': 5579, 'tossing': 5580, 'paragraph': 5581, 'gem': 5582, 'plumped': 5583, 'affection': 5584, 'wearer': 5585, 'gaol': 5586, 'plausible': 5587, 'intellectual': 5588, 'attained': 5589, 'inferences': 5590, 'advertise': 5591, 'eaten': 5592, 'legible': 5593, 'roasting': 5594, 'humanity': 5595, 'million': 5596, 'instruction': 5597, 'crumpled': 5598, 'entreated': 5599, 'silver': 5600, '700': 5601, 'ghastly': 5602, '4d': 5603, '26s': 5604, 'endured': 5605, 'detained': 5606, 'cake': 5607, 'charged': 5608, 'bathsponge': 5609, 'dream': 5610, 'heap': 5611, 'cushions': 5612, 'unthinkable': 5613, 'roads': 5614, 'signetring': 5615, 'roared': 5616, 'leatherhead': 5617, 'galvanised': 5618, 'welllit': 5619, 'blonde': 5620, 'control': 5621, 'clink': 5622, 'middlesex': 5623, 'lights': 5624, 'solved—what': 5625, 'devote': 5626, 'feasible': 5627, 'hoard': 5628, 'greasy': 5629, 'antecedents': 5630, 'necktie': 5631, 'secondfloor': 5632, 'company’s': 5633, 'expecting': 5634, 'brewer': 5635, 'tax': 5636, 'rifts': 5637, 'hoofs': 5638, 'vilest': 5639, 'prey': 5640, 'enemy': 5641, 'views': 5642, 'senility': 5643, 'looselipped': 5644, 'motion': 5645, 'lassitude': 5646, '19th': 5647, 'berth': 5648, 'charcoal': 5649, 'shadows': 5650, 'wharves': 5651, 'cheery': 5652, 'school': 5653, 'lighthouse': 5654, 'equinoctial': 5655, 'wight': 5656, 'easterly': 5657, 'origin': 5658, 'dates': 5659, 'calhoun': 5660, 'trademark': 5661, 'succeeded': 5662, 'loaf': 5663, 'landingstages’': 5664, 'steamboats': 5665, 'stormy': 5666, 'openshaw’s': 5667, 'subdued': 5668, 'seen—': 5669, 'date’': 5670, 'braving': 5671, 'georgia': 5672, 'persecution': 5673, 'fulfilment': 5674, 'solitude': 5675, 'analysis': 5676, 'boxer': 5677, 'unsystematic': 5678, 'region': 5679, 'botany': 5680, 'philosophy': 5681, 'rightly': 5682, 'rare': 5683, 'sittingrooms': 5684, 'cuvier': 5685, 'sholtos': 5686, 'smokerings': 5687, '‘never’': 5688, 'parties': 5689, 'augustine': 5690, 'notices': 5691, 'enigmatical': 5692, 'prendergast': 5693, 'london—eastern': 5694, '‘death': 5695, 'chalkpit': 5696, 'clanging': 5697, 'skull': 5698, 'abound': 5699, 'forebodings': 5700, 'sort’': 5701, 'nonsense’': 5702, 'from’': 5703, 'loudly': 5704, 'civilised': 5705, 'destroyed’': 5706, 'them’': 5707, 'register’': 5708, '2nd': 5709, 'abuse': 5710, 'basin': 5711, 'sensation': 5712, 'bars': 5713, 'lawyer’': 5714, 'invariably': 5715, 'quicktempered': 5716, 'competence': 5717, 'patentee': 5718, 'blaze': 5719, 'appeal': 5720, 'successes': 5721, 'cards': 5722, 'distinctive': 5723, 'vacant': 5724, 'landlady’s': 5725, 'encourage': 5726, 'luxurious': 5727, 'partially': 5728, 'hail’': 5729, 'highway': 5730, 'chronic': 5731, 'decrepitude': 5732, 'rotterdam': 5733, 'moss': 5734, '140': 5735, 'enables': 5736, 'lefthandedness': 5737, 'lame': 5738, 'lameness': 5739, 'expound': 5740, 'unfinished': 5741, 'hardheaded': 5742, 'uses': 5743, 'wears': 5744, 'corresponds': 5745, 'jutting': 5746, 'veins': 5747, 'is—': 5748, 'warmth': 5749, 'suffered': 5750, 'madly': 5751, 'strengthen': 5752, 'lestrade’s': 5753, 'ample': 5754, 'mines': 5755, 'union': 5756, 'defiantly': 5757, 'concern': 5758, 'repeatedly': 5759, 'tea': 5760, 'leatherleggings': 5761, 'lean': 5762, 'whither': 5763, 'same’': 5764, 'wood’': 5765, 'so’': 5766, 'body’': 5767, 'there’': 5768, 'was’': 5769, 'gone’': 5770, 'help’': 5771, 'arise': 5772, 'allusion': 5773, 'matter’': 5774, 'hanged': 5775, 'healthy': 5776, 'selfrestraint': 5777, 'informing': 5778, 'positively': 5779, 'earth—': 5780, 'flowers': 5781, 'wooded': 5782, 'depose': 5783, 'firmly': 5784, 'crowder': 5785, 'perplexity': 5786, 'difficulties': 5787, 'mile': 5788, 'eighteen': 5789, 'granted': 5790, 'paradoxical': 5791, 'rack': 5792, 'biassed': 5793, 'bell': 5794, '1115': 5795, 'gallows': 5796, 'deserved': 5797, 'constraint': 5798, 'suitor': 5799, 'communicated': 5800, 'expressed': 5801, 'masked': 5802, 'petty': 5803, 'stammered': 5804, 'glitter': 5805, 'transparent': 5806, 'bland': 5807, 'baryta': 5808, 'unravel': 5809, 'milk': 5810, 'interim': 5811, 'conclusive': 5812, 'neat': 5813, 'sewn': 5814, 'thumbnails': 5815, 'instructive': 5816, 'cloudwreaths': 5817, 'accurate': 5818, 'pancras': 5819, 'king’s': 5820, 'street—and—': 5821, '60': 5822, 'duchess': 5823, 'intricate': 5824, 'acknowledge': 5825, 'crude': 5826, 'writers': 5827, 'continents': 5828, 'artistic': 5829, 'unprofitable': 5830, 'stale': 5831, 'identity': 5832, 'sand': 5833, 'tout’': 5834, 'expenditure': 5835, 'fatal': 5836, '‘please’': 5837, 'derbies': 5838, 'effective': 5839, 'coattails': 5840, 'bags': 5841, 'tearing': 5842, 'area': 5843, 'terminated': 5844, 'rubber': 5845, 'gloomily': 5846, 'peajacket': 5847, 'peter': 5848, 'man—a': 5849, 'glare': 5850, 'armed': 5851, 'editions': 5852, 'keenwitted': 5853, 'conundrums': 5854, 'violinland': 5855, 'quitted': 5856, 'stagnant': 5857, 'sleepers': 5858, 'beds': 5859, 'strand': 5860, 'smokeladen': 5861, 'shabbygenteel': 5862, 'absorbing': 5863, 'cheap': 5864, 'applicant': 5865, 'paul’s’': 5866, 'him’': 5867, 'yesterday’': 5868, '‘yes’': 5869, '4’': 5870, 'elsewhere': 5871, 'laughter': 5872, 'roar': 5873, 'rueful': 5874, '1890': 5875, 'tomorrow’': 5876, 'billet’': 5877, 'time’': 5878, 'nominal’': 5879, 'work’': 5880, 'week’': 5881, 'pay’': 5882, 'mornings': 5883, 'payday': 5884, 'two’': 5885, 'you’': 5886, 'duties’': 5887, 'bachelor’': 5888, 'summoned': 5889, 'family’': 5890, 'league’': 5891, 'pounds’': 5892, 'apply’': 5893, 'do’': 5894, 'occupations’': 5895, 'vacancies’': 5896, 'into’': 5897, 'gets': 5898, 'asks': 5899, 'narratives': 5900, 'man’': 5901, 'cooking': 5902, 'rabbit': 5903, 'eligible': 5904, 'planted': 5905, 'tattoo': 5906, 'breastpin': 5907, 'developed': 5908, 'carpenter': 5909, 'drab': 5910, 'obese': 5911, 'recommence': 5912, 'doubting': 5913, 'disease': 5914, 'embellish': 5915, 'helper': 5916, 'cordially': 5917, 'honourable': 5918, 'amazement': 5919, 'tout': 5920, 'departed': 5921, 'continent': 5922, 'toast': 5923, 'jewelbox': 5924, 'marm': 5925, 'hospital': 5926, 'burgled': 5927, 'mouths': 5928, 'prepare': 5929, 'cigarshaped': 5930, 'legal’': 5931, 'come’': 5932, 'horses': 5933, 'shabby': 5934, 'gross': 5935, 'campaign': 5936, 'lent': 5937, 'noting': 5938, 'bijou': 5939, 'surface': 5940, 'drunkenlooking': 5941, 'inextricable': 5942, 'tied': 5943, 'cabinet': 5944, 'expenses': 5945, 'blanche': 5946, 'anxiety': 5947, 'progress': 5948, 'kramm': 5949, 'go—none': 5950, 'reproachfully': 5951, 'mad—insane': 5952, 'indiscretion': 5953, 'imitated': 5954, 'seal': 5955, 'authenticity': 5956, 'certificates': 5957, 'how—': 5958, 'pillow': 5959, 'warsaw—yes': 5960, '1858': 5961, 'fishes': 5962, 'furnish': 5963, 'docketing': 5964, 'adventuress': 5965, 'lengthy': 5966, 'incognito': 5967, 'dryly': 5968, 'august': 5969, 'history': 5970, 'obstinacy': 5971, 'vizard': 5972, 'client—': 5973, 'boswell': 5974, 'whistled': 5975, 'doubts': 5976, 'numerous': 5977, '‘remarkable': 5978, '‘gesellschaft’': 5979, 'exaggerated': 5980, 'residing': 5981, 'aloud': 5982, 'careless': 5983, 'drugcreated': 5984, 'silhouette': 5985, 'bosom': 5986, 'secret’': 5987, 'wellremembered': 5988, 'good’': 5989, 'ambition': 5990, 'flung': 5991, 'homecentred': 5992, 'right’': 5993, 'sensitive': 5994, 'finely': 5995, 'thoughtful': 5996, 'gibe': 5997, '': 5998, '<UNK>': 5999}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Test Case\n",
        "assert len(vocab) == VOCAB_SIZE\n",
        "assert len(dataset_tokens) == len(dataset_ids)\n",
        "assert torch.is_tensor(dataset_ids)\n",
        "print('Sample Test passed', '\\U0001F44D')"
      ],
      "metadata": {
        "id": "pcfdgSEai10g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2fbb8cd-2748-4780-b632-df8358c03b45"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Test passed 👍\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our data is ready, we need to find a way to feed it into the model. As you have learnt in the previous assignment, we use mini batch sampling for inputs into the model. PyTorch uses a dataloader class(which you used in your previous assignment) which makes this possible. This next function will be an emulation of the dataloader in vanilla Python."
      ],
      "metadata": {
        "id": "FJKBUpzy8Jcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(datapoints, labels, num_batches, batch_size):\n",
        "  '''\n",
        "    Function to create the dataloader which will yield batches on the fly.\n",
        "\n",
        "    Arguments:\n",
        "      datapoints: The preprocessed datapoints in the corpus\n",
        "      labels: The labels per datapoint\n",
        "      num_batches: The number of batches from the dataset\n",
        "      batch_size: The number of datapoints per batch\n",
        "    Returns:\n",
        "      x: One minibatch of input indices of size (batch_size, seq_len)\n",
        "      y: One minibatch of labels per datapoints of size (batch_size, 1)\n",
        "  '''\n",
        "  for i in range(num_batches):\n",
        "    if i == num_batches - 1:\n",
        "      x = datapoints[i*batch_size:]\n",
        "      y = labels[i*batch_size:]\n",
        "    else:\n",
        "      x = datapoints[i*batch_size: (i+1)*batch_size]\n",
        "      y = labels[i*batch_size: (i+1)*batch_size]\n",
        "    yield x, y"
      ],
      "metadata": {
        "id": "jrLu-dxj717y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling [5.5M]"
      ],
      "metadata": {
        "id": "WfEKhLJI8xBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step would be to build an RNN cell. This would be randomly initialised. An RNN contains 5 matrices, each of which have been described in the docstring. You would return a dictionary with the values being the matrices and keys being their corresponding notations. \n",
        "\n",
        "The equations of an RNN can be summarised as:\n",
        "\n",
        "### $ h^{(t)} = tanh(E \\cdot I) + h^{(t - 1)} \\cdot H + I_b $\n",
        "###  $ o^{(t)} = h^{(t - 1)} \\cdot O + O_b$"
      ],
      "metadata": {
        "id": "g5anN1Pr86a3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED - 0.75 Marks\n",
        "def create_rnn(hidden_len, emb_dim):\n",
        "\t'''\n",
        "\t\tCreates a randomly intialised rnn cell\n",
        "\t\t\n",
        "\t\tArguments:\n",
        "\t\t\thidden_len: The length of the hidden state of the rnn\n",
        "\t\t\temb_dim: The length of the embeddings in the embedding space\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\trnn: A dictionary containing all the weights and biases associated with the rnn cell (use torch.randn).\n",
        "\t\t\t\trnn['I']: The learnable weights to convert the input embeddings to the current hidden state\n",
        "\t\t\t\trnn['H']: The learnable weights to convert the previous hidden state to the current hidden state\n",
        "\t\t\t\trnn['O']: The learnable weights to convert the current hidden state to the output vector\n",
        "\t\t\t\trnn['I_b']: The bias to be used to convert the input embeddings to the current hidden state\n",
        "\t\t\t\trnn['O_b']: The bias to be used to convert the current hidden state to the output vector\n",
        "\t'''\n",
        "\t# YOUR CODE HERE\n",
        "\trnn= {'I': torch.randn(emb_dim,hidden_len),\n",
        "\t      'H': torch.randn(hidden_len,hidden_len),\n",
        "\t\t\t\t'O': torch.randn(hidden_len, hidden_len),\n",
        "\t\t\t\t'I_b': torch.randn(hidden_len,1),\n",
        "\t\t\t\t'O_b': torch.rand(hidden_len,1)}\n",
        "\t\n",
        "\treturn rnn"
      ],
      "metadata": {
        "id": "p27i3TB61mUA"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model input, as discussed before, is going to be a set of indices corresponding to each token in the vocabulary. This cannot be directly fed in because they do not mean anything to our model. They are not present in a common vector space. For this purpose, we create \"embeddings\" which is a multi-dimensional representation of our vocabulary. These are stored in a lookup table and are learnable features, just like the weights and biases of our network. They can be indexed using the indices we have created in our vocab.\n",
        "\n",
        "\n",
        "You have to write a function to initialise this lookup table, as per the conditions given in the docstring. The ```load_pretrained_embeddings``` loads the GloVe Embeddings for you in a dictionary mapping the GloVe tokens to GloVe embeddings."
      ],
      "metadata": {
        "id": "3PrP3gNR9fHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pretrained_embeddings(model_name):\n",
        "  '''\n",
        "\t\tReads and loads the pretrained glove embeddings from the downloaded glove file\n",
        "\t\t\n",
        "\t\tArguments:\n",
        "\t\t\tmodel_name: The path to the pretrained glove file\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tembedding_model: Mapping from token to its correpsonding glove embedding\n",
        "\t'''\n",
        "  embedding_model = {}\n",
        "  f = open(model_name, 'r')\n",
        "  for line in tqdm(f.readlines(), desc = 'Reading GloVe Embeddings'):\n",
        "    tmp = line.split(' ')\n",
        "    word, vec = tmp[0], list(map(float, tmp[1:]))\n",
        "    assert(len(vec) == 50)\n",
        "    if word not in embedding_model:\n",
        "        embedding_model[word] = torch.tensor(vec)\n",
        "        \n",
        "  return embedding_model\n",
        "\n",
        "# GRADED - 1.75 Marks\n",
        "def create_embeddings(emb_dim, num_tokens, vocab, model_name = 'glove.6B.50d.txt'):\n",
        "  '''\n",
        "\t\tCreates and initialises the embeddings for the corpus:\n",
        "    1. If a token in the corpus is present as a token in the glove embeddings, initialise it with the glove embedding\n",
        "    2. If a token in the corpus is not present as a token in the glove embeddings, initialise it with a random embedding sampled from U(-0.25, 0.25)\n",
        "    3. Initialise the padding token with a zero embedding\n",
        "\t\t\n",
        "\t\tArguments:\n",
        "\t\t\temb_dim: The length of the embeddings in the embedding space\n",
        "      num_tokens: The number of tokens in the vocabulary, aka, vocab size\n",
        "      vocab: Mapping from the word to its corresponding vocab index\n",
        "      model_name: The path to the pretrained glove file\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tembeddings: The initialised embedding space (a torch tensor)\n",
        "\t'''\n",
        "  # YOUR CODE HERE\n",
        "  glove_embeddings = load_pretrained_embeddings(model_name)\n",
        "  f = open(model_name, 'r')\n",
        "  r1=-.25\n",
        "  r2=.25\n",
        "  embeddings=[]\n",
        "  for word in vocab:\n",
        "    if word=='<PAD>':\n",
        "      embeddings.append(torch.zeros(50))\n",
        "    elif word in glove_embeddings:\n",
        "      embeddings.append(glove_embeddings[word])\n",
        "    else:\n",
        "      embeddings.append((r2-r1)*torch.randn(50)+r2)\n",
        "    \n",
        "\n",
        "  embeddings = torch.stack(embeddings)\n",
        "\n",
        "\n",
        "    \n",
        "  return embeddings"
      ],
      "metadata": {
        "id": "j-6VnNoO1c4q"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function creates your classifier, which is a fully connected layer. As before, you have to return a dictionary which contains the weights and baises of the classifier. The equations of the classifier can be summarised as:\n",
        "\n",
        " ### $ Y = (X \\cdot W + b)$"
      ],
      "metadata": {
        "id": "TTGHzEc0-5cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vlM3Es4ObpaP"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED - 0.75 Marks\n",
        "def create_classifier(in_features, num_classes):\n",
        "\t'''\n",
        "\t\tCreates a randomly intialised classifer as a fully connected layer\n",
        "\t\t\n",
        "\t\tArguments:\n",
        "\t\t\tin_features: The length of the feature vector at the input of the classifier\n",
        "\t\t\tnum_classes: The number of classes to be predicted\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tclassifier: \n",
        "\t\t\t\tclassifier['weight']: The randomly initialised weights for the fully connected layer from in_features to num_classes (use torch.randn)\n",
        "\t\t\t\tclassifier['bias']: The randomly initialised bias for the fully connected layer from in_features to num_classes\n",
        "\t'''\n",
        "\t# YOUR CODE HERE\n",
        "\tclassifier={'weight': torch.randn(in_features,num_classes),\n",
        "\t            'bias': torch.randn(num_classes,1)}\n",
        "\treturn classifier"
      ],
      "metadata": {
        "id": "7nzd7LvA1VJ3"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function forwards the rnn by one step for all elements in the batch. In case a padding token is encountered, no change is made to the output and the hidden state. For this purpose, you have been provided the previous hidden state and the previous output as an input into the function.\n",
        "\n",
        "### $ h^{(t)} = tanh(E \\cdot I) + h^{(t - 1)} \\cdot H + I_b $\n",
        "###  $ o^{(t)} = h^{(t - 1)} \\cdot O + O_b$"
      ],
      "metadata": {
        "id": "u4mHywfl_aH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED - 0.75 Marks\n",
        "def forward_rnn_one_step(rnn, embs, prev_hidden, prev_output):\n",
        "\t'''\n",
        "\t\tTakes one forward step through the rnn cell. In case a padding token is encountered, no change is made to the output and the hidden state.\n",
        "\t\t\n",
        "\t\tArguments:\n",
        "\t\t\trnn: Dictionary containing the weights and biases of the rnn\n",
        "\t\t\tembs: The input embeddings of the tokens of the datapoint\n",
        "\t\t\tprev_hidden: The previous hidden state\n",
        "\t\t\tprev_output: The previous outputs\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\thidden_state: The next hidden state\n",
        "\t\t\toutput: The output for this sequence\n",
        "\t'''\n",
        "\t# YOUR CODE HERE\n",
        "\tI = rnn[\"I\"]\n",
        "\tH = rnn[\"H\"]\n",
        "\tO = rnn[\"O\"]\n",
        "\tI_b = rnn[\"I_b\"]\n",
        "\tO_b= rnn[\"O_b\"]\n",
        "\n",
        "\thidden_state = torch.tanh(torch.matmul(embs,I)) + torch.matmul(prev_hidden,H) + torch.transpose(I_b,0,1)\n",
        "\toutput = torch.matmul(torch.transpose(prev_hidden,0,1),prev_output) + torch.transpose(O_b,0,1)\n",
        "\n",
        "\treturn hidden_state, output"
      ],
      "metadata": {
        "id": "5GQRtbVU1ep6"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below function passes your features through the full connected layer. The equations are summarised again for your convenience:\n",
        "\n",
        " $ Y = (X \\cdot W + b)$"
      ],
      "metadata": {
        "id": "2NFRrShZ_0lB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED - 0.75 Marks\n",
        "def classify(feat, classifier):\n",
        "\t'''\n",
        "\t\tPerforms a forward pass through the classifier\n",
        "\n",
        "\t\tArguments:\n",
        "\t\t\tfeat: The feature vector for classification\n",
        "\t\t\tclassifier: Dictionary containing the weights and biases of the classifier\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tlogits: The logits for each word in our model\n",
        "\t'''\n",
        "\t# YOUR CODE HERE\n",
        "\tw = classifier['weight']\n",
        "\tb = classifier['bias']\n",
        "\tlogits = torch.matmul(feat,w)+b\n",
        "\treturn logits"
      ],
      "metadata": {
        "id": "zAKtvg8V1g7P"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The forward function passes your input data through all the above functions in sequence. Note the sequential nature of calling the rnn, since the previous hidden state has to be used.\n",
        "\n",
        "The initial hidden state has to be initialised to zeros, while the output has to be randomly initialised.\n",
        "\n",
        "The features to be used for the classifier is the final output of the RNN. Note that the features can be a concatenations of all outputs/hidden states too. You will have to change the classifier accordingly. \n",
        "\n",
        "The output logits will have to be converted to a probability distribution. For this purpose, it will be passed through a softmax activation."
      ],
      "metadata": {
        "id": "SxbdiDe0AFPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x, seq_len, hidden_len, classifier, embs, rnn):\n",
        "\t'''\n",
        "\t\tPerforms a foraward pass for the batched data\n",
        "\n",
        "\t\tArguments:\n",
        "\t\t\tx: The feature vector for classification\n",
        "\t\t\tseq_len: The maximum permitted length of the token sequences in the datapoints\n",
        "\t\t\thidden_len: The length of the hidden state of the rnn cell\n",
        "\t\t\tclassifier: Dictionary containing the weights and biases of the classifier\n",
        "\t\t\tembs: The input embeddings of the tokens of the datapoint\n",
        "\t\t\trnn: Dictionary containing the weights and biases of the rnn\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tprobs: The probabilities of all the next words\n",
        "\t'''\n",
        "\tinput_embs = embs[x]\n",
        "\thidden_state = torch.zeros(x.shape[0], hidden_len)\n",
        "\toutput = torch.zeros(x.shape[0], hidden_len)\n",
        "\tfor i in range(seq_len):\n",
        "\t\thidden_state, output = forward_rnn_one_step(rnn, input_embs[:, i, :], hidden_state, output)\n",
        "\t\t\n",
        "\tlogits = classify(output, classifier)\n",
        "\tprobs = F.softmax(logits, dim = 1)\n",
        "\treturn probs"
      ],
      "metadata": {
        "id": "7x9Pma-P1j1J"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below cell to call your modelling functions."
      ],
      "metadata": {
        "id": "Q28VzfXeBbNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(69)\n",
        "print('Creating RNN')\n",
        "rnn = create_rnn(HIDDEN_LEN, EMB_DIM)\n",
        "print('Creating Embeddings')\n",
        "embs = create_embeddings(EMB_DIM, VOCAB_SIZE, vocab)\n",
        "print('Creating Classifier')\n",
        "classifier = create_classifier(HIDDEN_LEN, VOCAB_SIZE)"
      ],
      "metadata": {
        "id": "fNN-R2zRXNBC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "cb66dcd425314d559e42334070e4836b",
            "6265842f48be47c59e27aff3a8b3e1b4",
            "f0b00261996843c49b3cdff666e97bca",
            "ea6ab78e21e04255b2ab12971d01d7f3",
            "c8a3c29b045542928d93c5564287af11",
            "2f906bce1a9c4a1188c7ddb5a9ba2b6f",
            "a13d045a37684841b231a2a7aed7c78b",
            "d32bce16195c4d49afb2384f8fe06242",
            "5205f947d2d841718e063a1b011d700d",
            "dd3e011a41194319b0ce378525a1d40d",
            "91136809a253414588806501097481bc"
          ]
        },
        "outputId": "a123708d-13ff-4d38-9cc4-48c0c3b9c8d6"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating RNN\n",
            "Creating Embeddings\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reading GloVe Embeddings:   0%|          | 0/400000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb66dcd425314d559e42334070e4836b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Classifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Test Cases\n",
        "print(embs.shape)\n",
        "print((VOCAB_SIZE, EMB_DIM))\n",
        "assert rnn['H'].shape == (HIDDEN_LEN, HIDDEN_LEN)\n",
        "assert torch.isclose(rnn['I_b'][40], torch.tensor(0.1261), atol = 0.1) \n",
        "assert torch.isclose(rnn['I'][40][40], torch.tensor(0.9098), atol = 0.1) \n",
        "assert embs.shape == (VOCAB_SIZE, EMB_DIM)\n",
        "assert len(classifier['bias']) == VOCAB_SIZE\n",
        "print('Sample Test passed', '\\U0001F44D')"
      ],
      "metadata": {
        "id": "9oyK7TFckq5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6e257a-3c71-4b65-ad81-fda417a9706d"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6000, 50])\n",
            "(6000, 50)\n",
            "Sample Test passed 👍\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Test Cases\n",
        "torch.manual_seed(69)\n",
        "test_output, _ = forward_rnn_one_step(rnn, torch.randn(32, EMB_DIM), torch.zeros(32, HIDDEN_LEN), torch.zeros(32, HIDDEN_LEN))\n",
        "assert torch.isclose(test_output[1][0], torch.tensor(0.9958), atol = 0.01)\n",
        "print('Sample Test passed', '\\U0001F44D')"
      ],
      "metadata": {
        "id": "NAFTEyePFCYx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "a335734f-a14b-4002-8e06-a33f1aa76111"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-6f58664a031e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m69\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_rnn_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMB_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9958\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sample Test passed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\U0001F44D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that your data and model is ready, it is time to pass it through the model and get some predictions. Write an expression to calculate the number of batches and use that to create your dataloader, using the variables and prototype you have created above."
      ],
      "metadata": {
        "id": "3pd4vVHDBvR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED - 0.75 Marks\n",
        "num_batches = # YOUR CODE HERE\n",
        "dataloader = create_dataloader(dataset_ids, labels, num_batches, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "CInFhfcsBOdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like you do in PyTorch, loop through your dataloader to get the batches. Perform a forward pass to get the probabilities of your next words. Choose the most probable word using ```torch.argmax``` and add these to a list called ```preds```.\n",
        "\n",
        "These predictions will be indices, therefore, use ```vocab_inv``` to convert it back into words."
      ],
      "metadata": {
        "id": "GQIsUl-8B9wN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for x, y in tqdm(dataloader, total = num_batches, desc = 'Forward Pass'):\n",
        "  probs = forward(x, SEQ_LEN, HIDDEN_LEN, classifier, embs, rnn)\n",
        "  next_word = torch.argmax(probs, dim = 1)\n",
        "  preds.extend([vocab_inv[int(word)] for word in next_word])"
      ],
      "metadata": {
        "id": "ZokoQcq-p8gZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Test Case\n",
        "assert len(preds) == len(datapoints)\n",
        "print('Sample Test passed', '\\U0001F44D')"
      ],
      "metadata": {
        "id": "YfbJPR2mhN2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ETYZ2G1L6k_"
      },
      "source": [
        "# End of this part.\n",
        "Assignment by:\n",
        "\n",
        "Devaansh Gupta (f20190187@pilani.bits-pilani.ac.in)\n",
        "\n",
        "Palaash Agrawal (f20180565@pilani.bits-pilani.ac.in)\n",
        "\n",
        "Harsh Sulakhe (f20180186@pilani.bits-pilani.ac.in)\n",
        "\n"
      ]
    }
  ]
}